\documentclass[11pt]{article}
\usepackage[small]{titlesec}
\usepackage[top = 0.66in,textwidth = 6.5in, textheight=9.1in]{geometry}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{color}
\usepackage{amssymb}
\usepackage{accents}
\usepackage{tabularx}
\usepackage{fancyhdr}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{framed}
\usepackage[square,sort,comma,numbers]{natbib}
\usepackage{url}
\usepackage{float, subfig}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{amsthm}
\usepackage{grffile}
\usepackage{sidecap}
\usepackage{pbox}
\usepackage{algorithm}
\usepackage{longtable}
\usepackage[noend]{algpseudocode}

\def\qed{\hfill{\(\vcenter{\hrule height1pt \hbox{\vrule width1pt height5pt
				\kern5pt \vrule width1pt} \hrule height1pt}\)} \medskip}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\renewcommand{\textfraction}{0.0}
\newcommand{\dst}{\displaystyle}
\newcommand{\minx}{\mbox{\( \dst \min_{x \in X} \)}}
\newcommand{\Efx}{\mbox{\( \dst E f (x, \xi) \)}}
\newcommand{\Efxhat}{\mbox{\( \dst E f (\hat{x}, \xi) \)}}
\newcommand{\hxx}{\mbox{\( \hat{x} \)}}
\newcommand{\bpi}{\bar{\pi}}
\newcommand{\xx}{\mbox{\( x \)}}
\newcommand{\txxi}{\mbox{\(\xi\)}}
\newcommand{\var}{\mbox{var}}
\newcommand{\cF}{{\cal F}}
\newcommand{\cA}{{\cal A}}
\newcommand{\cG}{{\cal G}}
\newcommand{\cN}{{\cal N}}
\newcommand{\cO}{{\cal O}}
\newcommand{\txi}{{\xi}}
\newcommand{\PP}{\mbox{\(SP\)}}
\newcommand{\PPn}{\mbox{\(SP_n\)}}
\newcommand{\PPnx}{\mbox{\(SP_{n_x}\)}}
\newcommand{\noi}{\noindent}
\renewcommand{\ss}{\smallskip}
\newcommand{\ms}{\medskip}
\newcommand{\bs}{\bigskip}
\newcommand{\st}{\mbox{s.t.}}
\newcommand{\wpo}{\mbox{wp1}}
\newcommand{\iid}{\mbox{i.i.d.\ }}
\newcommand{\vsmo}{\vspace*{-0.1in}}
\newcommand{\vsmt}{\vspace*{-0.2in}}
\newcommand{\vso}{\vspace*{0.1in}}
\newcommand{\vst}{\vspace*{0.2in}}
\newcommand{\mc}{\multicolumn}
\newcommand{\cP}{{\cal P}}
\newcommand{\tcb}{\textcolor{blue}}
\newcommand{\underv}{\mbox{$\underbar{$v$}$}}
\newcommand*{\thead}[1]{\multicolumn{1}{c}}
\allowdisplaybreaks 

\renewcommand{\P}{{\mathbb P}}
\newcommand{\E}{{\mathbb E}}
\newcommand{\R}{{\mathbb R}}
\renewcommand{\Re}{{\mathbb R}}
\newcommand{\mbf}{\mathbf}
\renewcommand{\underbar}{\underaccent{\bar}}

\begin{document}
	%0.27
	\baselineskip0.25in
	
	\begin{center}
		\begin{large}
			\begin{bf}
				
				Optimal Crashing of an Activity Network with Disruptions \ms
				
				\today \ms
			\end{bf}
		\end{large}
	\end{center}

	\section{Introduction} \label{sec:introduction}
		The management of complex projects through optimization has a rich history in operations research, beginning with the critical path method of \citep{kelley1961criticalpath}; see \citet{soderlund2004building} for an overview. A project is a collection of activities, between which there are precedence relationships due to logical or technological considerations. A precedence relationship is usually reflected as the start time of one activity following the completion of another. Typically, multiple activities can be processed at the same time, and there is no limit on how many activities can be processed simultaneously, as long as the precedence requirements are satisfied. See~\citet{Elmaghraby77} for a detailed treatment of activity networks. In this setting, ``crashing" is an action that consumes a certain amount of one or more resources and shortens the duration of an activity accordingly~\citep{kuhl2008dynamic}. A deterministic optimization model for crashing an activity network was proposed in the 1960s \citep{fulkerson1961network, kelley1961criticalpath}, in which the goal is to complete the project in minimum time by allocating resources under one or more budget constraints.\\
		\newline
		When the program evaluation and review technique (PERT) was introduced~\citep{malcolm1959application}, activity durations were modeled as independent beta random variables, and the project duration approximated by a normal distribution. Extensions that allow for more general assumptions followed \citep{Elmaghraby77}, and Monte Carlo simulation plays a role in estimating the expected project span, which is difficult to express analytically \citep{burt1971conditional,van1963letter}. Heuristics and simulation-based algorithms have been developed to approximately solve the stochastic project crashing problem \citep{aghaie2009ant, bowman1994stochastic, ke2014genetic, kim2007heuristic}. Another approach to handle uncertainty in activity duration is robust optimization, in which the objective is to minimize the worst case project span over a specified uncertainty set. While affinely adaptive recourse decisions are computationally tractable as linear, or second-order cone, programs, this restriction may lead to suboptimal solutions \citep{chen2008linear, cohen2007stochastic}. However, once recourse decisions can take general form, the robust model is only tractable with rectangular uncertainty sets
		\citep{wiesemann2012robust}. \citet{ahipasaoglu2016distributionally} propose a distributionally robust optimization scheme applied to a PERT network, which reformulates the problem as a semidefinite program or a copositive program, depending on the description of uncertainty. The project crashing optimization problem finds application in project management~\citep{demeulemeester2006project, jaselskis1991allocation,tonchia2018industrial}, machine scheduling~\citep{blazewicz1983scheduling,hall1996machine}, health services scheduling~\citep{cardoen2010operating}, chemical processes~\citep{li2008process}, and digital circuit sizing~\citep{kim2007heuristic}.\\
		\newline
		In this paper, we propose using the concept of stochastic disruptions to model uncertainty in the duration of activities, which differs from existing approaches in both stochastic programming and robust optimization. A stochastic disruption is an event that may occur at any point in the problem's time horizon and results in a change---typically a significant change---in the system's parameters. A few authors apply this idea in models with discrete time periods, in which the disruption can only occur in a set of specified time periods. \citet{yu2004disruptionmgt} introduce scenario-based optimization models for airline scheduling. \citet{morton2009sealift} introduce a sealift scheduling problem under a finite number of stochastic disruptions within a stochastic programming structure; this model structure ``falls between standard two-stage and multi-stage stochastic programs for a multi-period problem" and reduces the size of the problem (scenario tree) to quadratic, rather than exponential, growth in the number of time periods. Our setting inherits the philosophy of \citet{morton2009sealift}, but enhances the model by allowing the random disruption time to be continuous in the context of an activity network, instead of a prespecified set of fixed time periods. \\
		\newline
		Given a limited number of disruption scenarios, the problem of optimizing crashing decisions to minimize expected completion time can be formulated as a stochastic mixed-integer program, and we present the model in Section~\ref{sec:formulation}. If we assume a continuous distribution for the disruption time and magnitude, a sample average approximation (SAA) can be used to create a finite set of scenarios and approximate the original problem by a finite-sized optimization problem. In Section~\ref{sec:nphard} we show that the problem is NP-hard even with continuous allocation of crashing effort and just two scenarios. Section~\ref{sec:examples} presents properties of the problem using a serial activity network as a special case. The potentially large scale and the discrete, non-convex nature of the SAA problem's formulation suggest that it may be computationally challenging to solve. In Section~\ref{sec:decomposition}, a method based on Benders' decomposition is developed to solve our problem of optimizing crashing decisions under stochastic disruptions. We show such a decomposition method can solve the integer program in a finite number of iterations. Experiment results are presented in Section~\ref{sec:results}, including the empirical relationship between solution quality and sample size, the comparison between the quality of our solution and solutions of alternative models, and the computational performance of the decomposition method of Section~\ref{sec:decomposition}. We conclude with remarks on potential extensions of our model in Section~\ref{sec:conclusions}.
	
	\section{Problem Formulation} \label{sec:formulation}
		{Nomenclature:}
		\begin{longtable}[H]{ l l l l }
			\multicolumn{4}{l}{\em Indices and index sets} \\
			\(I\) & \(\qquad\) & the set of activities;&\\
			\(J_i\) & \(\qquad\) & the set of crashing options for activity \(i \in I\);&\\
			\(\Omega\) & \(\qquad\) & the index set for disruption scenarios (sample space);&\\
			\(\cA\) &\(\qquad\) & set of arcs, which represents precedence relationships;&\\
			\\
			\multicolumn{4}{l}{\em Parameters} \\
			\(D_{ik}\)& \(\qquad\) & nominal duration between possible start times of activities \(i\) and \(k\), \((i,k) \in \cA\);&\\
			\(e_{ij}\) & \(\qquad\) & effectiveness of crashing option $j \in J_i$ for activity \(i \in I\);&\\
			\(B\) & \(\qquad\) & total budget for crashing options;&\\
			\(b_{ij}\) & \(\qquad\) & cost of crashing option \(j \in J_i\) for activity \(i \in I\);&\\
			\(H^\omega\) &\(\qquad\) & disruption time under scenario \(\omega \in \Omega\);&\\
			\(d_{ik}^\omega\) & \(\qquad\)& increase in duration of \((i,k) \in \cA\) under \(\omega \in \Omega\), if started after the disruption; &\\
			\(p^\omega\) & \(\qquad\) & the probability of scenario \(\omega \in \Omega\);& \\
			\(p^0\) & \(\qquad\) & the probability of no disruption;& \\
			\\
			\multicolumn{4}{l}{\em Decision variables}\\
			\(t_{i}\) & \(\qquad\) & nominal start time of activity \(i \in I\);&\\
			\(x_{ij}\) & \(\qquad\) & crashing of activity \(i \in I\) by option \(j \in J_i\) in the nominal plan; &\\
			\(t_{i}^\omega\) & \(\qquad\) & start time of activity \(i \in I\) under scenario \(\omega \in \Omega\);&\\
			\(x_{ij}^\omega\) & \(\qquad\) & crashing of activity \(i \in I\) by option \(j \in J_i\) under scenario \(\omega \in \Omega\); &\\
			\(G_i^\omega\) & \(\qquad\) & binary indicator whether activity \(i \in I\) starts after disruption under \(\omega \in \Omega\);&\\
			\(z_{ij}^\omega\) & \(\qquad\) & binary term to linearize bilinear term, \(G_i^\omega x_{ij}^\omega\), \(i \in I, j \in J_{i}, \omega \in \Omega\).&
		\end{longtable}
		\noi We first review an optimization model for a deterministic crashing problem; see~\citet{fulkerson1961network, kelley1961criticalpath}. A set of activities, \(I\), together with precedence relationships, \(\cA \subseteq I \times I\), form an acyclic activity network \(\mathcal{G} = (I,\cA)\), which represents the project. An arc \((i,k) \in \cA\) indicates that activity \(i\) has to finish before activity \(k\) starts, and its length, \(D_{ik}\), shows that the start time of activity \(i\) has to be at least \(D_{ik} \ge 0\) before the start time of activity \(k\). We create two dummy activities \(S, T \in I\) to represent the start and the termination of the entire project. Activity \(S\) should precede every activity \(i \in I \backslash \{S\}\) and \(T\) should succeed every activity \(i \in I \backslash \{T\}\), either directly or by implication, and they both have zero duration.
		
		We can apply a finite set of crashing options, \(j \in J_i\), to activity \(i \in I\). One unit application of each option incurs a cost of \(b_{ij}\), and it decreases the corresponding durations by \(D_{ik}e_{ij},\ \forall (i,k) \in \cA\), where \(e_{ij} \in [0,1]\) denotes the unit effectiveness of crashing option \(j\). For example, suppose the duration between the start time of activity \(1\) and \(2\) is \(D_{12} = 10\), and applying one unit of crashing option \(1\) to activity \(1\) decreases the duration by half; i.e., \(e_{11} = 0.5\). If we apply \(0.4\) unit of crashing option \(1\) to activity \(1\), \(x_{11} = 0.4\), the required separation between activity \(1\) and \(2\) becomes \(10(1 - 0.4 \cdot 0.5) = 8\). The total cost of crashing cannot exceed a given budget, \(B\). The objective is then to minimize the start time of activity \(T\), and thus, we formulate the deterministic project crashing problem as:
		\begin{subequations} \label{prob:static}
			\begin{align}
			\min \quad & t_T &\\
			\text{s.t.} \quad &  t_k - t_i \geq D_{ik}\left(1 - \sum_{j \in J_i} e_{ij} x_{ij} \right) \qquad \qquad \forall \,(i,k) \in \cA \label{cons:dSep}\\
			& \sum_{i \in I} \sum_{j \in J_i} b_{ij}x_{ij} \leq B  \label{cons:dBudget}\\
			& \sum_{j \in J_i} x_{ij} \leq 1  \qquad \qquad \forall \,i \in I \label{cons:dSingleBudget}\\
			& 0 \le x_{ij} \leq 1  \qquad \qquad \forall \,i \in I, j \in J_i \label{cons:dxub}\\
			& t_i \geq 0 \qquad \qquad \qquad \;\, \forall\, i \in I. \label{cons:dNonnegt}
			\end{align}
		\end{subequations}
		In this formulation, \(t_i\) represents the start time of activity \(i \in I\). We aim to minimize the project span, which is the start time of the terminal activity, \(t_T\). Constraint~\eqref{cons:dSep} guarantees the precedence relationship: if activity \(i\) precedes activity \(k\), activity \(k\) cannot start until time \(t_i + D_{ik} (1- \sum_{j \in J_i} e_{ij} x_{ij})\). Constraint~\eqref{cons:dBudget} is the budget constraint and constraint~\eqref{cons:dSingleBudget} ensures that no more than one unit of crashing option can be applied to an activity. Constraint~\eqref{cons:dNonnegt} enforces nonnegativity for the start time of all activities.\\
		\newline
		For a project crashing problem under stochastic disruptions, we assume at most one stochastic disruption can occur at a random time in the project span. While this assumption may be limiting in some settings, it is appropriate when it is unlikely for two or more disruptions to occur during the time horizon, and can apply, e.g., for natural disasters, major market crashes, cyber attacks, and work stoppages. For example, suppose we manage a construction project, and we aim to plan against the potential hazard caused by an earthquake or an employee strike. It may be unlikely for two major earthquakes or strikes to affect the same project within the relevant time period. We further assume that for each activity \(i \in I\), the crashing decision needs to be made prior to the start of that activity, which is reasonable, e.g., when contracts are involved in commitment of resources~\citep{oberlender1993project}. We assume a disruption does not affect activities that have already started (including those already finished) at the time of the disruption, but the disruption changes the length of activities that have not yet started according to a known probability distribution. It is usually hard to compute the recourse function directly when random parameters have a continuous distribution, and therefore we use sample average approximation (SAA)~\citep{kim2015guide,shapiro2009lectures}. In this paper, we assume there is a finite set of scenarios indexed by \(\omega \in \Omega\). For each scenario \(\omega\), the random realization of parameters, which we denote \(\xi^\omega\), consists of the timing of the disruption, \(H^\omega\), and the magnitude of the disruption via increases in the duration parameters, \(d^\omega_{ik}, \forall (i,k) \in \cA\). \\
		\newline
		Because we assume at most one disruption, we can model the problem as a two-stage stochastic mixed integer program, in which the timing of the second stage is random. That is, the definition of our stages differs from the usual stochastic programming setting. Here the first stage contains decisions through completion of the project, and we follow this policy if no disruption occurs. And, the second stage characterizes the decisions for each realization of the disruption, which commence at the random time, $H^\omega$. The first stage decision variables are carried out until the disruption if it ever occurs, and after the disruption, the scenario-specific recourse decisions are executed.\\
		\newline
		The extensive formulation of the two-stage stochastic program is shown as formulation~\eqref{prob:extensive}:
		\begin{subequations} \label{prob:extensive}
			\begin{align}
			\min \quad & p^0 t_T + \sum_{\omega \in \Omega} p^\omega t_T^\omega \\
			\text{s.t.} \quad & t_k - t_i \geq D_{ik} \left ( 1 - \sum_{j \in J_i} e_{ij} x_{ij} \right ) \qquad \qquad \forall \, (i,k) \in \cA \label{cons:Sep}\\
			& \sum_{i \in I} \sum_{j \in J_i} b_{ij}x_{ij} \leq B  \label{cons:Budget}\\
			& \sum_{j \in J_i} x_{ij} \leq 1  \qquad \qquad \forall \,i \in I \label{cons:SingleBudget}\\
			& H^\omega + G_i^\omega M \geq t_i \qquad \qquad \forall \,i \in I, \omega \in \Omega \label{cons:G1}\\
			& H^\omega - (1 - G_i^\omega) M \leq t_i \qquad \qquad \forall \,i \in I, \omega \in \Omega \label{cons:G2}\\
			& t_i^\omega + G_i^\omega M_t \geq t_i \qquad \qquad \forall \,i \in I, \omega \in \Omega \label{cons:tG1}\\
			& t_i^\omega - G_i^\omega M_t \leq t_i \qquad \qquad \forall \,i \in I, \omega \in \Omega \label{cons:tG2}\\
			& x_{ij}^\omega + G_i^\omega \geq x_{ij} \qquad \qquad \forall \,i \in I, j \in J_i, \omega \in \Omega \label{cons:xG1}\\
			& x_{ij}^\omega - G_i^\omega \leq x_{ij} \qquad \qquad \forall \,i \in I, j \in J_i, \omega \in \Omega \label{cons:xG2}\\
			& t_k^\omega - t_i^\omega \geq D_{ik} + d_{ik}^\omega G_i^\omega -\sum_{j \in J_i} D_{ik} e_{ij} x_{ij}^\omega - \sum_{j \in J_i} d_{ik}^\omega e_{ij} z_{ij}^\omega \qquad  \forall \,(i,k) \in \cA, \omega \in \Omega \label{cons:scenSep}\\
			& \sum_{i \in I}\sum_{j \in J_i} b_{ij}x_{ij}^\omega \leq B \qquad \qquad \forall \,\omega \in \Omega \label{cons:scenBudget}\\
			& \sum_{j \in J_i} x_{ij}^\omega \leq 1 \qquad \qquad \forall \,i \in I, \omega \in \Omega \label{cons:scenBudget1}\\
			& z_{ij}^\omega \leq G_i^\omega \qquad \qquad \forall \,i \in I, j \in J_i, \omega \in \Omega \label{cons:linearize1}\\
			& z_{ij}^\omega \leq x_{ij}^\omega \qquad \qquad \forall \,i \in I, j \in J_i, \omega \in \Omega \label{cons:linearize2}\\
			& z_{ij}^\omega \geq G_i^\omega + x_{ij}^\omega - 1 \qquad \qquad \forall \,i \in I, j \in J_i, \omega \in \Omega \label{cons:linearize3}\\
			& t_i \geq 0 \qquad \qquad \forall \,i \in I \label{cons:nonnegt}\\
			& t_i^\omega \geq H^\omega G_i^\omega \qquad \qquad \forall\, i \in I, \omega \in \Omega \label{cons:extra} \\
			& 0 \leq x_{ij} \leq 1 \qquad \qquad \forall \,i \in I, j \in J_i\\ 
			& 0 \leq x_{ij}^\omega \leq 1 \qquad \qquad \forall \,i \in I, j \in J_i, \omega \in \Omega\\
			& 0 \leq z_{ij}^\omega \leq 1 \qquad \qquad \forall \,i \in I, j \in J_i, \omega \in \Omega\\
			& G_i^\omega \in \{0,1\}. \qquad \qquad \forall \,i \in I, \omega \in \Omega.
			\end{align}
		\end{subequations}
		In model~\eqref{prob:extensive}, we minimize the expected project span, weighing the span under each scenario by its probability. We replicate constraints~\eqref{cons:dSep}-\eqref{cons:dSingleBudget} for the nominal scenario as~\eqref{cons:Sep}-\eqref{cons:SingleBudget}. In constraints~\eqref{cons:G1}-\eqref{cons:G2}, variable \(G^\omega_i\) takes value \(1\) if activity \(i\) starts after the disruption time; otherwise it takes value 0, and \(M\) is a large number to enforce the logic of this relationship. This is important in our problem setting because the duration of each activity depends on its temporal relationship to the disruption time, which is reflected in constraint~\eqref{cons:scenSep}. Also, we must ensure that decisions made before the disruption time in each scenario match the nominal decisions, and constraints~\eqref{cons:tG1}-\eqref{cons:xG2} capture these non-anticipativity conditions. For each scenario, the duration between activity \(i\) and \(k\) becomes \((D_{ik} + d_{ik}^\omega G_i^\omega)(1 - \sum_{j \in J_i} e_{ij}x_{ij}^\omega)\), which expands to the form of constraint~\eqref{cons:scenSep}. If \(G_i^\omega = 0\), which means activity \(i\) starts before the disruption time of scenario \(\omega\), this expression is the same as \(D_{ik} (1 - \sum_{j \in J_i} e_{ij}x_{ij})\) because \(x_{ij} = x_{ij}^\omega\) is enforced by constraints~\eqref{cons:xG1} and~\eqref{cons:xG2}. If \(G_i^\omega = 1\), then the duration between activity \(i\) and \(k\) is changed to \(D_{ik} + d_{ik}^\omega \ge 0\). We allow a negative ``increase'' in duration $d_{ik}^\omega$, but require the overall duration to be nonnegative. The expression \((D_{ik} + d_{ik}^\omega G_i^\omega)(1 - \sum_{j \in J_i} e_{ij}x_{ij}^\omega)\) contains a bilinear term \(G_i^\omega x_{ij}^\omega\), which we linearize using binary variable \(z_{ij}^\omega\) and constraints \eqref{cons:linearize1}-\eqref{cons:linearize3}.
	
		
	\section{NP-Hardness} \label{sec:nphard}
		In this section, we prove that the project crashing optimization problem under a stochastic disruption is NP-hard. The proof process is largely based on the proof of De et al.~1997 for the discrete time-cost tradeoff (\verb|DTCT|) problem. In De et al.~\cite{de1997complexity}, the authors show that an exactly-one-in-three \verb|3SAT| (\verb|EOIT_3SAT|) problem can be transformed to an instance of the \verb|DTCT| decision problem in polynomial time. Since \verb|EOIT_3SAT| is NP-complete (see \cite{Garey1979ComputersAI} for the detailed proof), the authors prove that the \verb|DTCT| decision problem is also NP-complete, and the \verb|DTCT| optimization problem is NP-hard.\\
		\newline
		Similar to De et al.~\cite{de1997complexity}, we also first introduce the \verb|EOIT_3SAT| problem: let \(U = \{u_1,u_2, \dots, u_n\}\) be a set of variables. A literal can be either \(u\) or \(\bar{u} = \neg u\) for a \(u \in U\). Let \(C = \{c_1, c_2, \dots, c_m\}\) be a set of clauses, each of which is formed by a disjunction of three literals. The \verb|EOIT_3SAT| problem asks for whether there is a truth assignment for \(U\) such that each clause in \(C\) has exactly one true literal. \\
		\newline
		Based on the above instance of \verb|EOIT_3SAT|, we formulate an instance of the activity network for the project crashing problem. The activity network consists of three layers of nodes: the first layer contains \(3n\) nodes and represents the truth assignment of each variable; the second layer contains \(3m\) nodes and represents the value of clauses; the third layer contains node \(T\) which represents the end of the project. The first layer has \(n\) components in parallel, each of which corresponds to a variable and contains 3 nodes connected, denoted as \(u_{j1},\ u_{j2}\) and \(u_{j3}\) for the component \(j\), as shown in Figure~\ref{fig:layer1}. Figure~\ref{fig:layer1} also displays how the first layer connects to the third layer. We set the scenario set as a singleton \(\Omega = \{1\}\) and set the disruption time as \(H^1 = 0\) with probability \(p^1 = 1\). We set parameter values associated with the arcs in Figure~\ref{fig:layer1} as:
		\begin{align*}
		& D_{u_{j1},u_{j2}} = 1 \qquad \quad d^1_{u_{j1},u_{j2}} = 1\\
		& D_{u_{j1},u_{j3}} = 2 \qquad \quad d^1_{u_{j1},u_{j3}} = -1  \\
		& D_{u_{j3},T} = 0 \qquad \quad \;\; d^1_{u_{j3},T} = 0.
		\end{align*}
		We do not allow any activities within the first layer to be crashed, i.e., \(J_{u_{jk}} = \emptyset\), for all \(j = 1,2,\dots, n,\ k = 1,2,3\). With this setup, the length of the critical path for the \(j\)-th component is always \(2\) for all \(j = 1,2,\dots,n\), as it is optimal to have activity \(u_{j1}\) start at time \(0\). However, whether the critical path traverses activities \(u_{j2}\) (top path) or the activity \(u_{j3}\) (bottom path) depends on the value of \(G^1_{u_{j1}}\). If \(G^1_{u_{j1}} = 1\), the \(G\) variables will take value \(1\) for all subsequent nodes. The top path yields a length of \(D_{u_{j1},u_{j2}} + d^1_{u_{j1},u_{j2}} = 1 + 1 = 2\), while the bottom path yields a length of \(D_{u_{j1},u_{j3}} + d^1_{u_{j1},u_{j3}} = 2 - 1 = 1\), which makes the top path critical. If \(G^1_{u_{j1}} = 0\), it is optimal to have activity \(u_{j2}\) start before the disruption as well, i.e., \(G^1_{u_{j2}} = 0\). The top path yields a length of \(D_{u_{j1},u_{j2}} = 1\), while the bottom path yields a length of \(D_{u_{j1},u_{j3}} = 2\), which makes the bottom path critical. We can consider the value of \(G^1_{u_{j1}}\) as the truth assignment of variable \(u_j\). If the variable \(u_j\) is TRUE, the critical path is the top path; if it is FALSE, the critical path is the bottom path. 
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.6\textwidth]{layer1}
			\caption{A component corresponding to variable \(u_j,\ j = 1,2,\dots, n\) in the first layer of the constructed activity network for \texttt{EOIT\char`_3SAT}.}
			\label{fig:layer1}
		\end{figure}
		\noi The arcs from activities \(u_{j2}\) and \(u_{j3}\) in Figure~\ref{fig:layer1} point to activities in the second layer. Next, we construct the second layer of activities and the arcs connecting the first layer and the second layer, in a similar manner as Figure 2(b) in~\cite{de1997complexity}. To best illustrate the arc construction, we show an example of a clause, \(c_i = u_j \vee u_k \vee \bar{u}_{\ell}\), with two original variables, \(u_j\) and \(u_k\), and one negative complement, \(\bar{u}_{\ell}\). We can consider the activity \(c_{ip}\) corresponding to the truth assignment of the variable \(u_p\), for \(p \in \{j,k,\ell\}\). For the original variables \(u_p\), \(p \in \{j,k\}\), we connect activity \(u_{p3}\) with activity \(c_{ip}\), and activity \(u_{p2}\) with activities \(c_{iq}\), where \(q \in \{j,k,\ell\}, q \neq p\). For the negative complement variable \(u_\ell\), we connect activity \(u_{\ell 2}\) with activity \(c_{i \ell}\), and activity \(u_{\ell 3}\) with activities \(c_{iq},\ q \in \{j,k\}\). This example by no means limits the clauses to two variables and one negative complement but aims to showcase the procedure of constructing the network components corresponding to a variable and the negative complement of a variable. From now on we refer to the activities representing variables as \(u\)-activities and those representing clauses as \(c\)-activities.\\
		\newline
		We let both the nominal duration \(D\) and the disrupted effect \(d\) for the arcs between \(u\)-activities and \(c\)-activities be \(0\). For the arcs between \(c\)-activities and \(T\), we set:
		%The parameters of arcs in Figure~\ref{fig:layer2} are set as:
		\begin{align*}
		& D_{c_{iq},T} = 1 \qquad \quad \;\; d^1_{c_{iq},T} = 0 \;\;\;\quad \forall q \in \{j,k,\ell\}.
		\end{align*}
		Unlike the \(u\)-activities, each \(c\)-activity can be crashed with a single option with effectiveness \(e_{c_{ip}1} = 1\), \(\forall p \in \{j,k,\ell\}\). The total budget, \(B\), is then set to \(B = 2m\), where \(m\) is the total number of clauses.
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\textwidth]{layer2}
			\caption{The \(i\)-th clause, \(u_{j} \vee u_{k} \vee \bar{u}_{\ell}\), in the second layer of the constructed activity network for \texttt{EOIT\char`_3SAT} with the arcs connecting it with the first and the third layer.}
			\label{fig:layer2}
		\end{figure}
		\noi For simplicity, the reasoning behind this construction is stated using the example in Figure~\ref{fig:layer2}: for variable \(u_j\), if \(G^1_{u_{j1}} = 1\), the activity \(u_{j4}\) can start at time \(1\), while the earliest time the activity \(u_{j3}\) can start is \(2\). If \(G^1_{u_{j1}} = 0\), the activity \(u_{j3}\) can start at time \(1\), while the earliest time the activity \(u_{j4}\) can start is \(2\). This is the same for variable \(u_k\) but directly opposite for variable \(u_\ell\). The truth assignments indicate which path is critical, which is similar in De et al.~\cite{de1997complexity}, where the truth assignments indicate which crashing option to select for variables nodes. \\
		\newline
		We can prove the following lemmas. Without loss of generality, a clause can be made of without negative complement of variables. For clarity, Figure~\ref{fig:layer2} equivalent for a clause without negative complement is displayed as Figure~\ref{fig:layer2nonneg}, which is used to illustrate the proofs for Lemma~\ref{lemma:onlyOne} and Lemma~\ref{lemma:iff}.
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\textwidth]{layer2nonneg}
			\caption{The \(i\)-th clause, \(u_{j} \vee u_{k} \vee u_{\ell}\), in the second layer of the constructed activity network for \texttt{EOIT\char`_3SAT} with the arcs connecting it with the first and the third layer.}
			\label{fig:layer2nonneg}
		\end{figure}
		\begin{lemma} \label{lemma:onlyOne}
			For any clause \(c_i = u_j \vee u_k \vee u_\ell,\ i = 1,2,\dots,m\), there is at most one activity \(c_{iq^*},\ q^* \in \{j,k,\ell\}\) that has the earliest start time as \(1\), and the start time for \(c_{iq}\) is \(2\), for \(q \in \{j,k,\ell\}, q \neq q^*\).
		\end{lemma}
		\begin{proof}[Proof of Lemma \ref{lemma:onlyOne}]
			Without loss of generality, suppose both \(c_{ij}\) and \(c_{ik}\) can start at time \(1\). This means that both \(u_{j2}\) and \(u_{j3}\) needs to start at time \(1\), which is impossible because no matter what value \(G^1_{u_{j1}}\) takes, at least one activity in \(\{u_{j2},u_{j3}\}\) has to start after time \(2\).
		\end{proof}
		\begin{lemma} \label{lemma:iff}
			For any clause \(c_i = u_j \vee u_k \vee u_\ell,\ i = 1,2,\dots,m\), one activity \(c_{iq^*},\ q^* \in \{j,k,\ell\}\) has the earliest start time as \(1\) if and only if variable \(\{u_{q^*}\}\) is the only variable in the clause to which the truth assignment is TRUE.
		\end{lemma}
		\begin{proof}[Proof of Lemma \ref{lemma:iff}]
			Without loss of generality, we assume \(q^* = j\).\\
			\(\implies\):  Suppose \(u_j\) is FALSE, then activity \(u_{j3}\) can only start after time \(2\), which will lead to the contradiction that \(c_{ij}\) can start as early as time \(1\). Suppose either \(u_k\) or \(u_\ell\) is TRUE in addition to \(u_j\). Since there is going to be an arc from either activity \(u_{k2}\) or \(u_{\ell 2}\) to activity \(c_{ij}\), and either \(u_{k2}\) or \(u_{\ell 2}\) cannot start before time \(2\), it leads to a contradiction that \(c_{ij}\) can start as early as time \(1\). Therefore, if activity \(c_{ij}\) can start at time \(1\), then \(u_j\) is the only variable which is TRUE.\\
			\(\impliedby\): if only \(u_j\) is TRUE, then \(u_{j3}, u_{k2}\) and \(u_{\ell 2}\) can all start as early as time \(1\), which means that the earliest start time of \(c_{ij}\) is \(1\).
		\end{proof}
		\noi A direct result from Lemma~\ref{lemma:iff} shows if there exists a truth assignment that meets the requirement of \verb|EOIT_3SAT|, there are at most \(2m\) number of \(c\)-activities (2 per clause) that has to start after time \(2\). Since we have a total of \(B = 2m\) units of resource, we can crash all of those \(c\)-activities to achieve a project length of \(2\). This means that we can transform an \verb|EOIT_3SAT| problem to a project crashing decision problem under a stochastic disruption using the activity network construction process above. If we can find a feasible \verb|EOIT_3SAT| assignment, it is possible to obtain a project length less than or equal to 2. Next, we show the formal NP-hardness proof of the project crashing problem with a stochastic disruption. We first formally define the project crashing decision problem under a stochastic disruption:
		\begin{definition}
			A project crashing decision problem under a stochastic disruption is: if we solve is model~\ref{prob:extensive}, there a feasible \(\{t,x,G\}\) such that the optimal expected project length is smaller than or equal to \(\mathcal{T}\).
		\end{definition}
		\begin{theorem}\label{thm:npcomplete}
			For an instance of the \verb|EOIT_3SAT| problem, we construct the corresponding project crashing decision problem under a stochastic disruption: let \(\Omega = \{1\}\), \(H^1 = 0\), \(\mathcal{T} = 2\), and the precedence relationships, the crashing options and budget are constructed by the process shown in the Section~\ref{sec:nphard}. This decision problem has a solution if and only if the given instance of \verb|EOIT_3SAT| problem has a solution.
		\end{theorem}
		\begin{proof}[Proof of Theorem~\ref{thm:npcomplete}]
			(polynomial transformation) 
			%We first show that any instance of the project crashing decision problem is constructed in time that is polynomial in the length of the given instance of \verb|EOIT_3SAT|, and has a length that is polynomially related to the length of that instance. 
			Suppose the \verb|EOIT_3SAT| problem has \(n\) variables and \(m\) clauses, the constructed activity network for the project crashing problem has \(4n + 3m + 1\) activities and \(5n + 12m\) arcs, which are both polynomial in the size of the original \verb|EOIT_3SAT| problem. And all numbers in the project crashing decision problem are smaller than a constant, \(2\).\\
			(\(\implies\)) Suppose the \verb|EOIT_3SAT| instance has a solution. We have shown that we can start every activity as early as possible, and spend the budget to crash all \(c\)-activities which correspond to the literals with FALSE assignment and have the start time at \(2\). \\
			(\(\impliedby\)) Suppose the project crashing decision problem has a solution \((\hat{t},\hat{x},\hat{G})\) where \(t_T = 2\). By Lemma~\ref{lemma:onlyOne} we know that for each clause there are at most one \(c\)-activity that can start at time \(1\), which means in total there must be at least \(2m\) number of \(c\)-activities with a start time later than \(2\). Since the crashing budget is exactly \(2m\), if there are more than \(2m\) \(c\)-activities that starts after time \(2\), the project length will be larger than 2, which means that there are exactly \(2m\) number of \(c\)-activities starting at time \(2\). This is equivalent to that exactly one \(c\)-activity in each of the \(m\) clauses starts at time \(1\). From Lemma~\ref{lemma:iff} we can directly obtain the result that for each clause there is exactly one variable to which the truth assignment is TRUE, which is essentially a solution to the \verb|EOIT_3SAT| instance.\\
			\newline
			\verb|EOIT_3SAT| is a NP-complete problem~\cite{Garey1979ComputersAI}. The project crashing decision problem under a stochastic disruption in NP, since we can check in \(O(n^2)\) to check whether a given input is feasible and has \(t_T \leq \mathcal{T}\). This complete the proof that the project crashing decision problem under a stochastic disruption is NP-complete.
		\end{proof}
		\begin{theorem} \label{thm:nphard}
			The project crashing optimization problem under a stochastic disruption is NP-hard.
		\end{theorem}
		\begin{proof}[Proof of Theorem~\ref{thm:nphard}]
			From Theorem~\ref{thm:npcomplete} states that the project crashing decision problem under a stochastic disruption is NP-complete. This implies the project crashing optimization problem under a stochastic disruption, formulated as model~\ref{prob:extensive}, is NP-hard.
		\end{proof}
	
\section{Illustration of Problem Properties via Examples} \label{sec:examples}
	We show two examples of serial activity networks to give insight regarding the nature of the project crashing problem under a stochastic disruption, and to draw distinctions relative to its deterministic counterpart. In the deterministic project crashing problem, all activities on the critical path should start as soon as possible. However, with a stochastic disruption, it is sometimes optimal to delay the start of one or more activities. In addition, under a stochastic disruption, it is possible that on a critical path, an activity with a shorter expected duration is crashed with a larger amount of resource, while in the deterministic case, it is always optimal to crash the activity with the longest duration on the critical path, under equal $b_{ij}$ and $e_{ij}$ values. We use two examples to show that the deterministic optimal solution can be significantly inferior in the stochastic setting because of these two properties. Here, we assume that required duration that separates the start of activity \(i\) and the start of a successor, \(k\), only depends on $i$; i.e., for each activity \(i\) we use \(D_i\) to denote the duration of activity \(i\) and \(d_i^\omega\) to denote the change in duration under scenario \(\omega\):
	\begin{align*}
	& D_{ik} = D_i \qquad \qquad \forall (i,k) \in \cA\\
	& d^{\omega}_{ik} = d^{\omega}_i \qquad \qquad \forall (i,k) \in \cA, \omega \in \Omega.
	\end{align*}
	Clearly delaying the start of an activity may be beneficial when \(d_i^\omega < 0\) for some \(i \in I, \omega \in \Omega\) because the expected decrease in duration may exceed the delay required to move the start of activity \(i\) after a potential disruption. In the following example, we show value of delay, even if all activities are lengthened by the disruption; i.e., \(d_i^\omega > 0, \forall i \in I, \omega \in \Omega\).
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.4\textwidth]{serial2}
		\caption{Example of a 2-activity serial network project}
		\label{fig:serial2}
	\end{figure}
	\begin{example} \label{eg:delay}
		Consider a network with two activities in series, as shown in Figure~\ref{fig:serial2} with $I=\{S,1,2,T\}$, and let parameter \(k > 4\). Let the nominal durations be $D_1 = k$ and $D_2 = 1$. We assume only one crashing option for each activity, and so we omit index $j$. We let $e_1=e_2=1 - \frac{1}{2k}$, assume $b_i=1$ for all $i \in I$, and we let $B=1$. Let $\Omega=\{1\}$ so that either we have no disruption with probability $p^0=1 - \frac{1}{k}$, or we have a disruption that occurs at time $\varepsilon < \frac{1}{2}$ with probability $p^1=\frac{1}{k}$. If a disruption occurs, the nominal activity durations are lengthened by $d_1 = k$ and $d_2 = (k - 1)^2$. \\
		\newline
		If we start each activity without delay, then \(t_1 = 0,\ x_1=x_1^1\), and for any \(x_1 \leq 1\), \(t_2 \geq \frac{1}{2} \geq D_1(1 - e_1 x_1) \), which means activity \(2\) will start after the disruption. Since \(k > 1\), the duration of activity~\(1\), $D_1 = k$, exceeds the expected duration of activity 2, $ D_2 + p^1 d_2 = 1 + \frac{1}{k} (k-1)^2 = k - 1 + \frac{1}{k}$. As a result, it is optimal to spend the entire budget on activity \(1\): $x_1=x_1^1=1$ and $x_2=x_2^1=0$, and the expected project duration is: 
		\begin{align*}
		&D_1 (1 - e_1 x_1) + p^0 D_2 + p^1 (D_2 + d_2) \\
		= & k \left(1 - \left (1 - \frac{1}{2k} \right )\cdot 1 \right) + (1 - \frac{1}{k}) \cdot 1 + \frac{1}{k} \left(1 + (k -1)^2\right) \\
		= & k - \frac{1}{2} + \frac{1}{k}.
		\end{align*}
		On the other hand, if we delay the start of activity 1 until $t_1= \varepsilon$ then $x_1$ and $x_1^1$ need not be equal. Since for \(k > 2 + \sqrt{2}\), $k = D_1 > D_2 = 1$ and $(k - 1)^2 + 1 = D_2+d_2 > D_1 + d_1 = k + k$, we have $x_1=1$, $x_1^1=0$, $x_2^1=1$ in an optimal solution, and the expected duration is:
		\begin{align*}
		&\varepsilon + p^0 \left[D_1 \cdot \left(1 - (1 - \frac{1}{2k}) \cdot 1 \right) + D_2 \right]  + p^1 \left[(D_1 + d_1) + \left(1 - (1 - \frac{1}{2k}) \cdot 1 \right) (D_2 + d_2) \right]\\
		= & \varepsilon + \frac{k - 1}{k} \left(k \cdot \frac{1}{2k} + 1\right) + \frac{1}{k} \left[ (k + k) + \frac{1}{2k} \left((k-1)^2 + 1\right) \right] \\
		= & \varepsilon + 4 - \frac{5}{2k} + \frac{1}{k^2}.
		\end{align*}
	\end{example}
	In Example~\ref{eg:delay} if require that activity~1 be started without delay then the objective function grows to infinity with $k$, but the optimal project span by delaying the start of activity~1 by $\varepsilon$ has a constant limit of \(\varepsilon + 4\). This example shows that the gap between the optimal solution under a no-delay policy and an optimal solution that allows for delay---as we do in model~\eqref{prob:extensive}---can be arbitrarily large. Because it is possible for an optimal crashing plan to contain a delay for some activities, model~\eqref{prob:extensive} uses decision variables \(t_i,\ \forall i \in I\), as the start time of each activity, rather than assuming that each activity starts as soon as all of its predecessors are finished. 
	%In summary, the reasons for such delay include:
	%		\begin{enumerate}
	%			\item Some activities might have a shorter length after the disruption. It is beneficial to wait a short period of time to capture this advantage.
	%			\item Even if all possible disruption magnitudes are adverse, which means they lengthen all activities, it is beneficial to delay an activity so that the crashing resource could be optimally applied according to the realization of disruption.
	%		\end{enumerate}
	\begin{example} \label{eg:short}
		We again consider the network with two activities from Figure~\ref{fig:serial2}. Let $D_2 > D_1$, $d_1=0$, $d_2 > 0$, $e_1=e_2=\frac{1}{2}$, and $B=1$. We again consider a single disruption scenario, $\Omega=\{1\}$, so that either we have no disruption, $p^0=\frac{1}{2}$, or we have a disruption that occurs at time $H^1=\frac{1}{2}D_1$ with probability $p^1=\frac{1}{2}$. Here, the optimal solution is to crash the shorter activity, i.e., $x_1=1$, which yields an expected project span of $\frac{1}{2}D_1 + D_2$ with start times $t_1=0$ and $t_2=\frac{1}{2}D_1$. In contrast, if $0 \le x_1 < 1$ then the expected duration is $D_1 (1-\frac{1}{2} x_1) + (D_2 + \frac{1}{2} d_2)(1-\frac{1}{2} x_2)$, so that the ratio of the objective functions grows arbitrarily large as $d_2$ grows. 
	\end{example}
	
	\noi In Example~\ref{eg:short} the intuition behind crashing the shorter activity is that it allows us to initiate activity~2 in time to avoid incurring delay~$d_2$. Both examples in this section suggest that the intuition associated with the deterministic version of the optimal crashing problem does not always apply in the stochastic setting, and provides further motivation for employing a model like that in formulation~\eqref{prob:extensive}.
	
	\section{Decomposition Method} \label{sec:decomposition}
	Model~\eqref{prob:extensive} is a two-stage stochastic mixed integer program (2SMIP), which is large-scale and computationally expensive in general~\cite{ahmed2011smip}. We first follow the Benders' decomposition method to separate the model into a master problem \((M)\) and a set of subproblems \((S^\omega)\), \(\omega \in \Omega\). The state variables \(t\) and \(x\) are all continuous and binary variables exist in the recourse problems, which makes recourse problems nonconvex. 
	\begin{subequations}
		\label{prob:masterOri}
		\begin{align}
		(M) \quad z^* = \min \quad &p^0 t_T + \sum_{\omega \in \Omega} p^\omega f^\omega(t,x)\\
		\text{s.t.} \quad & t_k - t_i \geq D_{i}(1 - \sum_{j \in J_i} x_{ij} e_{ij}) \qquad \qquad \forall \,i \in I, (i,k) \in \mathcal{A} \label{cons:MSep}\\
		& \sum_{i \in I} \sum_{j \in J_i} b_{ij}x_{ij} \leq B  \label{cons:MBudget}\\
		& \sum_{j \in J_i} x_{ij} \leq 1  \qquad \qquad \forall \,i \in I \label{cons:MSingleBudget}\\
		& t_i \geq 0 \qquad \qquad \forall \,i \in I\\
		& 0 \leq x_{ij} \leq 1 \qquad \qquad \forall \,i \in I, j \in J_i. \label{cons:Mxbounds}
		\end{align}
	\end{subequations}
	\begin{subequations}
		\label{prob:subOri}
		\begin{align}
		(S^\omega) \qquad f^\omega(\hat{t},\hat{x}) = \min \quad & t_T \\
		& H^\omega + G_i M \geq \hat{t}_i \qquad \qquad \forall \,i \in I \label{cons:sG1}\\
		& H^\omega - (1 - G_i) M \leq \hat{t}_i \qquad \qquad \forall \,i \in I \label{cons:sG2}\\
		& t_i + G_i M_t \geq \hat{t}_i \qquad \qquad \forall \,i \in I \label{cons:stG1}\\
		& t_i - G_i M_t \leq \hat{t}_i \qquad \qquad \forall \,i \in I \label{cons:stG2}\\
		& x_{ij} + G_i \geq \hat{x}_{ij} \qquad \qquad \forall \,i \in I, j \in J_i \label{cons:sxG1}\\
		& x_{ij} - G_i \leq \hat{x}_{ij} \qquad \qquad \forall \,i \in I, j \in J_i \label{cons:sxG2}\\
		& t_k - t_i \geq D_i + d_i^\omega G_i -\sum_{j \in J_i} D_i e_{ij} x_{ij} - \sum_{j \in J_i} d_i^\omega e_{ij} z_{ij} \nonumber \\ 
		& \qquad \qquad \forall \,i \in I, j \in J_i \label{cons:subSep}\\
		& \sum_{j \in J_i} x_{ij} \leq 1 \qquad \qquad \forall \,i \in I \label{cons:subBudget1}\\
		& \sum_{i \in I}\sum_{j \in J_i} b_{ij}x_{ij} \leq B \qquad \qquad \forall \,\omega \in \Omega \label{cons:subBudget}\\
		& z_{ij} \leq G_i \qquad \qquad \forall \,i \in I, j \in J_i \label{cons:sublinearize1}\\
		& z_{ij} \leq x_{ij} \qquad \qquad \forall \,i \in I, j \in J_i \label{cons:sublinearize2}\\
		& z_{ij} \geq G_i + x_{ij} - 1 \qquad \qquad \forall \,i \in I, j \in J_i \label{cons:sublinearize3}\\
		& t_i \geq H^\omega G_i \qquad \qquad \forall\, i \in I \label{cons:subH}\\
		& 0 \leq x_{ij} \leq 1 \qquad \qquad \forall \,i \in I, j \in J_i\\
		& 0 \leq z_{ij} \leq 1 \qquad \qquad \forall \,i \in I, j \in J_i\\
		& G_i \in \{0,1\}. \qquad \qquad \forall \,i \in I. \label{cons:subInt}
		\end{align}
	\end{subequations}
	Most of the previous literature of stochastic mixed integer programming assumes a special structure or property which cannot be applied to our problem setting. For example, Gade et al. \cite{gade2014decomposition} solve 2SMIPs with pure binary first stage variables using a sequential convex approximation of recourse by a branch-and-cut process framework where Gomory cuts are added. Ahmed et al. \cite{zou2016nested} assume state variables to be binary so that the Lagrangian cuts are a tight approximation of the recourse function. Car{\o}e and Tind \cite{caroe1998shaped} solves a more general case of 2SMIP by using the MIP duality theory but the practical tractability is not verified. Qi and Sen \cite{qi2017ancestral} have mixed integer variables in both the master and the recourse problems. Parametric disjunctive cuts, derived in Chen et al. \cite{chen2012computational}, are generated to convexify recourse problems while Benders' cuts approximate recourse value functions. Although this method suits our problem settings, we implement it only to find that it does not converge in a reasonable time frame. Therefore, we need a new decomposition method that utilizes the special structure of our problem. \\
	\newline
	We can relax the integrality constraints~\eqref{cons:subInt} and perform Benders' decomposition on the relaxed problem. Benders' cuts provide a valid lower approximation of the recourse function \(f^\omega(t,x), \forall \omega \in \Omega\) but may not be tight. In each iteration of the Benders' decomposition, an upper bound can be obtained by evaluating the subproblems~\eqref{prob:subOri} with the first stage solution. The main challenge is how to gradually tighten the lower approximation while quickly locate a good upper bound, and all topics in this section aim to tackle either aspect of this challenge.
	\subsection{Partitioning-based Decomposition Method} \label{subsec:partition}
	The relaxation quality is poor since a big-\(M\) needs to be incorporated in our recourse problems to represent the logical condition whether the starting time of activity \(i\) is before or after the disruption time. A smaller big-\(M\) yields a tighter relaxation and helps prevent numerical issues~\cite{camm1990cutting,klotz2013practical}. We can rewrite constraints~\eqref{cons:sG1} and~\eqref{cons:sG2} as:
	\begin{equation} \label{cons:Grange}
	(\hat{t}_i - H^\omega)/M \leq G_i \leq (\hat{t}_i - H^\omega)/M + 1
	\end{equation}
	and \(G_i\) can take a wider range of value when \(M\) is larger. Therefore, sequentially tightening \(M\) is helpful to generate a tighter lower bound as the algorithm progresses. Eventually, if for a scenario we can fix the \(G_i\) for all \(i \in I\) to either 0 or 1, the Benders' cuts will be tight.\\
	\newline
	From now on we assume the scenarios \(\omega \in \Omega\) are ordered according to their time \(H^\omega\) in an ascending order. We can also observe that if we know \(\hat{t}_i \geq H^{\omega'_i}\) for some \(\omega'_i\), \(G_i\) has to take value 1 in all subproblem \(S^\omega\) where \(\omega < \omega'_i\). On the other hand if we know \(\hat{t}_i \leq H^{\omega'_i}\) for some \(\omega'_i\), \(G_i\) has to take value 0 in all subproblem \(S^\omega\) where \(\omega > \omega'_i\). These observations inform us that by bounding the value of first stage variable \(t_i,\ \forall i \in I\), we can determine the value of \(G_i\) in many subproblems, which strengthens the Benders' cuts.\\
	\newline
	We propose a decomposition algorithm to solve model~\eqref{prob:extensive}. Our method partitions the continuous feasible region of the master problem by introducing of a set of binary variables. As we refine the partition of \(t\)-space, we can generate tightened Benders' cuts to approximate the recourse function. For any crashing optimization problem, we can bound the first stage \(t_i\) variables by lower bound \(0\) and upper bound \(T_{\max} = H^{|\Omega|} + t_T^0\), where \(t_T^0\) is the longest \(S\)-\(T\) path of activity network \(\mathcal{G} = (I,\mathcal{A})\) and the arc length of \((i,j) \in \mathcal{A}\) equals to \(D_i\). This means that suppose the optimal solution of model~\eqref{prob:extensive} is denoted as \((t^*,x^*,G^{*,\cdot},t^{*,\cdot},x^{*,\cdot})\), the latter two representing the scenario specific start time and crashing decisions, we have:
	\begin{proposition} \label{prop:bounds}
		\(t^*_i \in [0,T_{\max}],\ \forall i \in I\).
	\end{proposition}
	\begin{proof}
		Constraint~\eqref{cons:nonnegt} enforces the lower bound of this proposition. \\
		\newline 
		To derive the upper bound, 
		we first establish a feasible solution \(\tilde{t}_i = H^{|\Omega|} + t^0_i,\ \forall i \in I\), \(\tilde{x}_{ij} = 0,\ \forall i \in I, j \in J_i\) and \(\tilde{G}_i^\omega = 1,\ \forall i \in I, \omega \in \Omega\), where \(t^0_i\) represents the length of the longest \(S\)-\(i\) path of \(\mathcal{G}\). 
		If we assume that there exists some \(i \in \tilde{I}\) such that \(t_i^* > T_{\max}\), we know \(T \in \tilde{I}\). There, we can keep \(x^*\), \(G^{*,\omega}\), \(t^{*,\omega}\) and \(x^{*,\omega}\) for all \(\omega \in \Omega\) the same, and replace the \(t_i^*\) by \(\tilde{t}_i\) for all \(i \in \tilde{I}\) without violating any constraints. This yields another feasible solution which has a smaller value of \(t_T^*\) since \(T \in \tilde{I}, \tilde{t}_T = T_{\max} < t_T^*\). Therefore the new objective value obtained by this feasible solution is smaller, which contradicts the assumption that \((t^*,x^*,G^{*,\cdot},t^{*,\cdot},x^{*,\cdot})\) is an optimal solution.
	\end{proof}
	\noi Proposition~\ref{prop:bounds} indicates that all \(t_i,\ \forall i \in I\) are bounded on an interval \([0,T_{\max}]\). Since there are precedence relationships between activities, the possible range of different activities' start time can be further limited. We first set up two parameters \(H^0 = 0\) and \(H^{|\Omega| + 1} = T_{\max}\) and then define a partition of this interval for each \(i \in I\) to exploit this limitation as follows:
	\begin{definition}
		For an activity \(i \in I\), the partition of interval \([0,T_{\max}]\) is denoted by \(\mathcal{P}_i\), which is an ordered set of two-element tuples %\((\underbar{\omega}^q,\bar{\omega}^q)\), 
		\((\underbar{H}^q,\bar{H}^q)\), 
		indexed by \(q \in \mathcal{Q}_i\). We use \(\underbar{H}^q\) to specify the lower bound of \(q\)-th element of the partition and \(\bar{H}^q\) to specify its upper bound. Each of them corresponds to a disruption time of some scenario.
		The partition has the following properties:
		\begin{itemize}
			%\item \(\underbar{\omega}^1 = 0\)
			\item \(\underbar{H}^1 = H^0 = 0\)
			%\item \(\bar{\omega}^{|\mathcal{Q}_i|} = T_{\max}\)
			\item \(\bar{H}^{|\mathcal{Q}_i|} = H^{|\Omega| + 1} = T_{\max}\)
			%\item \(\bar{\omega}^q = \underbar{\omega}^{q + 1}\).
			\item \(\bar{H}^q = \underbar{H}^{q + 1}\).
		\end{itemize}
	\end{definition}
	\noi A simple example of such partition can be illustrated in Figure~\ref{fig:simplePart}. In this example we have five scenarios \(\Omega = \{1,2,3,4,5\}\), ordered by the disruption time. The partition has three elements, each illustrated by a box with dashed lines and represent a part of the interval. For partition element \(1\), the lower bound scenario index is \(0\) and the upper bound scenario index is \(2\), which means the range corresponding to it is lower bounded by \(H^0 = 0\) and upper bounded by \(H^2\).
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{simplePart}
		\caption{An illustration of partition on interval \([0,T_{\max}]\).}
		\label{fig:simplePart}
	\end{figure}
	\noi For each activity \(i \in I\), with the partition \(\mathcal{P}_i\) defined, we can see the start time \(t_i\) of the master problem lies in the range specified by one element of \(\mathcal{P}_i\). We introduce an indicator \(y_i^q\), \(\forall i \in I, q \in \mathcal{Q}_i\) in the first stage:
	\begin{equation}
	y_i^q = \begin{cases}
	%1 & \text{if \(t_i \in [H^{\underbar{\omega}^q},H^{\bar{\omega}^q}]\)}\\
	1 & \text{if \(t_i \in [\underbar{H}^q,\bar{H}^q]\)}\\
	0 & \text{otherwise}
	\end{cases}
	\qquad \forall i \in I, q \in \mathcal{Q}_i,
	\end{equation}
	and we use the following constraints to represent this relationship:
	\begin{subequations} \label{cons:yCons}
		\begin{align}
		& \sum_{q \in \mathcal{Q}_i} \underbar{H}^q y_i^{q} \leq t_i \leq \sum_{q \in \mathcal{Q}_i} \bar{H}^q y_i^{q} \qquad \qquad \forall i \in I \label{cons:tyBounds}\\
		& \sum_{q \in \mathcal{Q}_i} y_i^q = 1 \qquad \qquad \forall i \in I. \label{cons:sumy1}
		\end{align}
	\end{subequations}
	In constraint~\eqref{cons:sumy1}, we enforce that \(t_i\) can only lie in one of the ranges specified by the partition, as only one of \(y_i^q\) can take value \(1\) for each \(i \in I\). Depending on the value of \(y_i^q\), we can write the bounds of the such range as in~\eqref{cons:tyBounds}. \\
	\newline
	The benefit of setting up the \(y\) variables is to obtain tighter bounds for \(t_i\) than the generic bounds \([0,T_{\max}]\) in Proposition~\ref{prop:bounds}. Suppose solving the master problem provides a solution \(\hat{y}_i^{\tilde{q}}, \forall i \in I, q \in \mathcal{Q}_i \). Then we can replace the big-\(M\) in constraints~\eqref{cons:sG1} and~\eqref{cons:sG2} of the scenario with moderate \(M_i^{\omega,+}\) and \(M_i^{\omega,-}\) because introducing variables \(y\) gives us better bounds on \(t_i\):
	\begin{subequations}
		\begin{align}
		& M_i^{\omega,+} = \sum_{q \in \mathcal{Q}_i} \bar{H}^q \hat{y}_i^q - H^\omega\\
		& M_i^{\omega,-} = H^\omega - \sum_{q \in \mathcal{Q}_i} \underbar{H}^q \hat{y}_i^q
		\end{align}
	\end{subequations}
	and the constraints~\eqref{cons:sG1} and~\eqref{cons:sG2} become:
	\begin{subequations} \label{cons:newBoundsm}
		\begin{align}
		H^\omega + G_i \left(\sum_{q \in \mathcal{Q}_i} \bar{H}^q \hat{y}_i^q - H^\omega \right) \geq \hat{t}_i \qquad \qquad \forall i \in I\\
		H^\omega - (1 - G_i) \left(H^\omega - \sum_{q \in \mathcal{Q}_i} \underbar{H}^q \hat{y}_i^q \right) \leq \hat{t}_i \qquad \qquad \forall i \in I.
		\end{align}
	\end{subequations}
	The multiplication of \(G_i \hat{y}_i^q\) makes the dual of subproblem no longer linear of \(y\). To fix this, since \(\hat{y}_i^q\) is binary and \(G_i\) for all \(i \in I, q \in \mathcal{Q}_i\), we can introduce variables \(F_i^q\) to linearize the bilinear term and rewrite constraints~\eqref{cons:newBoundsm} as follows:
	\begin{subequations} \label{cons:newBoundsmlin}
		\begin{align}
		H^\omega + \sum_{q \in \mathcal{Q}_i} \bar{H}^q F_i^q - H^\omega G_i \geq \hat{t}_i \qquad \qquad \forall i \in I \label{cons:FG1}\\
		G_i H^\omega - \sum_{q \in \mathcal{Q}_i} \underbar{H}^q F_i^q \leq \hat{t}_i - \sum_{q \in \mathcal{Q}_i} \underbar{H}^q \hat{y}_i^q \qquad \qquad \forall i \in I \label{cons:FG2}\\
		F_i^q \leq G_i \qquad \qquad \forall i \in I, q \in \mathcal{Q}_i \label{cons:FGlin1}\\
		F_i^q \leq \hat{y}_i^q \qquad \qquad \forall i \in I, q \in \mathcal{Q}_i \label{cons:FGlin2}\\
		F_i^q \geq G_i + \hat{y}_i^q - 1 \qquad \qquad \forall i \in I, q \in \mathcal{Q}_i. \label{cons:FGlin3}
		\end{align}
	\end{subequations}
	In the subproblem, for each activity \(i \in I\), there is only one \(\hat{q} \in \mathcal{Q}_i\) such that \(\hat{y}_i^{\hat{q}} = 1\), which means \(\hat{t}_i \in 
	%[H^{\underbar{\omega}^{\hat{q}}},H^{\bar{\omega}^{\hat{q}}}]\). 
	[\underbar{H}^{\hat{q}},\bar{H}^{\hat{q}}]\). 
	We examine the validity and effectiveness result of these tightened constraints. For validity, we check if constraints~\eqref{cons:newBoundsm} matches the logic when \(G_i\) is binary, while for effectiveness, we need to compare the feasible range of \(G\) in constraints~\eqref{cons:Grange} and that specified by constraints~\eqref{cons:newBoundsm}. \\
	\newline
	For a specific \(i \in I\), constraints~\eqref{cons:newBoundsm} can be rewritten using \(\hat{q}\):
	\begin{subequations} \label{cons:sGnew}
		\begin{align}
		%H^\omega + G_i \left( H^{\bar{\omega}^{\hat{q}}} - H^\omega \right) \geq \hat{t}_i \label{cons:sGnew1}\\
		%H^\omega - (1 - G_i) \left(H^\omega - H^{\underbar{\omega}^{\hat{q}}} \right) \leq \hat{t}_i. \label{cons:sGnew2}
		H^\omega + G_i \left( \bar{H}^{\hat{q}} - H^\omega \right) \geq \hat{t}_i \label{cons:sGnew1}\\
		H^\omega - (1 - G_i) \left(H^\omega - \underbar{H}^{\hat{q}} \right) \leq \hat{t}_i. \label{cons:sGnew2}
		\end{align}
	\end{subequations}
	For a scenario \(\omega \in \Omega\), there are three possible positions of \(H^\omega\) relative to this range with \(\hat{y}_i^{\hat{q}} = 1\): 
	%\(H^\omega \in [H^{\underbar{\omega}^{\hat{q}}},H^{\bar{\omega}^{\hat{q}}}]\), \(H^\omega < H^{\underbar{\omega}^{\hat{q}}}\), or \(H^\omega > H^{\bar{\omega}^{\hat{q}}}\). 
	\(H^\omega \in [\underbar{H}^{\hat{q}},\bar{H}^{\hat{q}}]\), \(H^\omega < \underbar{H}^{\hat{q}}\), or \(H^\omega > \bar{H}^{\hat{q}}\). 
	When \(G_i = 1\), the left-hand side of constraint~\eqref{cons:sGnew1} is \(\bar{H}^{\hat{q}}\) and the left-hand side of constraint~\eqref{cons:sGnew2} is \(H^\omega\). When \(G_i = 0\), the left-hand side of constraint~\eqref{cons:sGnew1} is \(H^\omega\), and the left-hand side of constraint~\eqref{cons:sGnew2} is 
	%\(H^{\underbar{\omega}^{\hat{q}}}\).
	\(\underbar{H}^{\hat{q}}\).
	\begin{enumerate}
		\item 
		\(H^\omega \in
		%[H^{\underbar{\omega}^{\hat{q}}},H^{\bar{\omega}^{\hat{q}}}]\): 
		[\underbar{H}^{\hat{q}},\bar{H}^{\hat{q}}]\): 
		we can see that if \(\hat{t}_i \geq H^\omega\), by logic \(G_i\) should take value \(1\). Constraints~\eqref{cons:sGnew} match \(\hat{t}_i \geq H^\omega\) for \(G_i = 1\) and is violated for \(G_i = 0\). Similar validity results hold if \(\hat{t}_i < H^\omega\). In addition, the possible value \(G_i\) can take changes from the one shown in~\eqref{cons:Grange} to:
		\begin{equation}
		%\left(\hat{t}_i - H^\omega \right)/\left( H^{\bar{\omega}^{\hat{q}}} - H^\omega \right) \leq G_i \leq (\hat{t}_i - H^\omega)/\left(H^\omega - H^{\underbar{\omega}^{\hat{q}}} \right) + 1
		\left(\hat{t}_i - H^\omega \right)/\left( \bar{H}^{\hat{q}} - H^\omega \right) \leq G_i \leq (\hat{t}_i - H^\omega)/\left(H^\omega - \underbar{H}^{\hat{q}} \right) + 1 \label{cons:case1}
		\end{equation}
		Since the value of \(M\) decreases compared to constraints~\eqref{cons:Grange}, when \(\hat{t}_i \geq H^\omega\), the lower bound increases and upper bound is \(1\). When \(\hat{t}_i < H^\omega\), the upper bound decreases and the lower bound is \(0\). Therefore, the feasible range of \(G_i\) for each \(i \in I\) shrinks, which achieves the goal to tighten the subproblem relaxation.
		\item 
		%\(H^\omega < H^{\underbar{\omega}^{\hat{q}}}\): 
		\(H^\omega < \underbar{H}^{\hat{q}}\): 
		we can see \(G_i = 1\) is feasible and \(G_i = 0\) violates constraint~\eqref{cons:sGnew1}. The possible value \(G_i\) can take becomes:
		\begin{subequations}
			\begin{align}
			%G_i \geq \left(\hat{t}_i - H^\omega \right)/\left( H^{\bar{\omega}^{\hat{q}}} - H^\omega \right)\\
			%G_i \geq (\hat{t}_i - H^\omega)/\left(H^\omega - H^{\underbar{\omega}^{\hat{q}}} \right) + 1.
			G_i \geq \left(\hat{t}_i - H^\omega \right)/\left( \bar{H}^{\hat{q}} - H^\omega \right) \label{cons:case2eqn1}\\
			G_i \geq (\hat{t}_i - H^\omega)/\left(H^\omega - \underbar{H}^{\hat{q}} \right) + 1. \label{cons:case2eqn2}
			\end{align}
		\end{subequations}
		Notice that the inequality~\eqref{cons:case2eqn2} is strictly weaker than~\eqref{cons:case2eqn1} because the right-hand side of~\eqref{cons:case2eqn2} is smaller than 0 while the right-hand side of~\eqref{cons:case2eqn1} is positive. Similar to Case 1, the lower bound increases compared to using a large \(M\) and the upper bound is \(1\), and we achieve a tightened relaxation.
		\item 
		%\(H^\omega > H^{\bar{\omega}^{\hat{q}}}\): 
		\(H^\omega > \bar{H}^{\hat{q}}\): 
		we can see \(G_i = 0\) is feasible and \(G_i = 1\) violates constraint~\eqref{cons:sGnew2}. The possible value \(G_i\) can take becomes:
		\begin{subequations}
			\begin{align}
			%G_i \leq \left(\hat{t}_i - H^\omega \right)/\left( H^{\bar{\omega}^{\hat{q}}} - H^\omega \right)\\
			%G_i \leq (\hat{t}_i - H^\omega)/\left(H^\omega - H^{\underbar{\omega}^{\hat{q}}} \right) + 1.
			G_i \leq \left(\hat{t}_i - H^\omega \right)/\left( \bar{H}^{\hat{q}} - H^\omega \right) \label{cons:case3eqn1}\\
			G_i \leq (\hat{t}_i - H^\omega)/\left(H^\omega - \underbar{H}^{\hat{q}} \right) + 1. \label{cons:case3eqn2}
			\end{align}
		\end{subequations}
		Notice that the inequality~\eqref{cons:case3eqn1} is always weaker than~\eqref{cons:case3eqn2} because the right-hand side of~\eqref{cons:case3eqn1} is greater than 1 while the right-hand side of~\eqref{cons:case3eqn2} is between 0 and 1. Similar to Case 1, the upper bound decreases compared to using a large \(M\) and the lower bound is \(0\), and we achieve a tightened relaxation.
	\end{enumerate}
	The tightened constraints~\eqref{cons:newBoundsm} is shown to have validity and effectiveness properties. However, for the latter two situations, 
	%\(H^\omega < H^{\underbar{\omega}^{\hat{q}}}\) and \(H^\omega > H^{\bar{\omega}^{\hat{q}}}\), 
	\(H^\omega < \underbar{H}^{\hat{q}}\) and \(H^\omega > \bar{H}^{\hat{q}}\), 
	\(G_i\) can still take fractional value. We further tighten the formulation by adding two constraints involving \(y\), such that if the subproblems belonging to those two situations, \(G_i\) can be fixed as either \(0\) or \(1\). For scenario \(\omega \in \Omega\), suppose solving the master problem provides the solution \(\hat{y}_i^q, \forall i \in I, q \in \mathcal{Q}_i\), we have:
	\begin{equation}\label{cons:subyG}
	%\sum_{q \in \mathcal{Q}_i, H^\omega \leq H^{\underbar{\omega}^q}} \hat{y}_i^q \leq G_i \leq 1 - \sum_{q \in \mathcal{Q}_i, H^\omega \geq H^{\bar{\omega}^q}} \hat{y}_i^q \qquad \forall i \in I 
	\sum_{q \in \mathcal{Q}_i, H^\omega \leq \underbar{H}^q} \hat{y}_i^q \leq G_i \leq 1 - \sum_{q \in \mathcal{Q}_i, H^\omega \geq \bar{H}^q} \hat{y}_i^q \qquad \forall i \in I 
	\end{equation}
	Again we check the validity and the effectiveness result of constraints~\eqref{cons:subyG} for the three situations listed above:
	\begin{enumerate}
		\item 
		%\(H^\omega \in [H^{\underbar{\omega}^{\hat{q}}},H^{\bar{\omega}^{\hat{q}}}]\): 
		\(H^\omega \in [\underbar{H}^{\hat{q}},\bar{H}^{\hat{q}}]\): 
		the lower bound is \(0\) since \(y_i^q = 0\) for all elements of partition left of \(\hat{q}\), and the upper bound is \(1\) because \(y_i^q = 0\) for all elements of partition right of \(\hat{q}\). Therefore, \(0 \leq G_i \leq 1\) is valid.
		\item 
		%\(H^\omega < H^{\underbar{\omega}^{\hat{q}}}\): 
		\(H^\omega < \underbar{H}^{\hat{q}}\): 
		the lower bound is \(1\) since the summation term, 
		%\(\sum_{q \in \mathcal{Q}_i, H^\omega \leq H^{\underbar{\omega}^q}} \hat{y}_i^q\), includes \(y_i^{\hat{q}}\), 
		\(\sum_{q \in \mathcal{Q}_i, H^\omega \leq \underbar{H}^q} \hat{y}_i^q\), includes \(y_i^{\hat{q}}\), 
		which forces \(G_i = 1\). This matches the logic since \(\hat{t}_i \geq H^\omega\).
		\item 
		\(H^\omega > \bar{H}^{\hat{q}}\): the upper bound is \(1\) since the summation term, \(\sum_{q \in \mathcal{Q}_i, H^\omega \geq \bar{H}^q} \hat{y}_i^q\), includes \(y_i^{\hat{q}}\), which forces \(G_i = 0\). This matches the logic since \(\hat{t}_i \leq H^\omega\).
	\end{enumerate}
	With the addition of constraints~\eqref{cons:newBoundsmlin} and~\eqref{cons:subyG} in the subproblems, we present the tightened version of subproblems as follows: 
	\begin{subequations}
		\label{prob:subTightened}
		\begin{align}
		(S_{\mathcal{P}}^\omega) \qquad f^\omega_{\mathcal{P}}(\hat{t},\hat{x},\hat{y}) = \min \quad & t_T \\
		\text{s.t.} \quad & \sum_{q \in \mathcal{Q}_i} \bar{H}^q F_i^q - H^\omega G_i \geq \hat{t}_i - H^\omega \qquad \qquad \forall i \in I \label{cons:sFG1t}\\
		& H^\omega G_i - \sum_{q \in \mathcal{Q}_i} \underbar{H}^q F_i^q \leq \hat{t}_i - \sum_{q \in \mathcal{Q}_i} \underbar{H}^q \hat{y}_i^q \qquad \qquad \forall i \in I \label{cons:sFG2t}\\
		& F_i^q \leq G_i \qquad \qquad \forall i \in I, q \in \mathcal{Q}_i \label{cons:sFGlin1t}\\
		& F_i^q \leq \hat{y}_i^q \qquad \qquad \forall i \in I, q \in \mathcal{Q}_i \label{cons:sFGlin2t}\\
		& F_i^q \geq G_i + \hat{y}_i^q - 1 \qquad \qquad \forall i \in I, q \in \mathcal{Q}_i. \label{cons:sFGlin3t}\\
		& G_i \geq \sum_{q \in \mathcal{Q}_i, H^\omega \leq \underbar{H}^q} \hat{y}_i^q \qquad \qquad \forall i \in I \label{cons:syG1t}\\
		& G_i \leq 1 - \sum_{q \in \mathcal{Q}_i, H^\omega \geq \bar{H}^q} \hat{y}_i^q \qquad \qquad \forall i \in I \label{cons:syG2t}\\
		& \text{Constraints~\eqref{cons:stG1}-\eqref{cons:subH}}\\
		& 0 \leq x_{ij} \leq 1 \qquad \qquad \forall \,i \in I, j \in J_i\\
		& 0 \leq z_{ij} \leq 1 \qquad \qquad \forall \,i \in I, j \in J_i\\
		& 0 \leq F_i^q \leq 1 \qquad \qquad \forall \,i \in I, q \in \mathcal{Q}_i\\
		& 0 \leq G_i \leq 1. \qquad \qquad \forall \,i \in I. \label{cons:G01t}
		\end{align}
	\end{subequations}
	Suppose we solve the subproblems \((S_{\mathcal{P}}^\omega)\) for every \(\omega \in \Omega\) and generate a linear cut indexed by \(\ell\), where coefficients \(\pi,\lambda\) and \(\gamma\) can be calculated based on the dual variables obtained:
	\begin{equation} \label{cons:cut}
	\theta^\omega \geq v^{\omega,\ell} + \sum_{i \in I} \pi_i^{\omega,\ell} (t_i - \hat{t}_i^{\ell}) + \sum_{i \in I} \sum_{j \in J_i} \lambda_{ij}^{\omega,\ell} (x_{ij} - \hat{x}_{ij}^{\ell}) + \sum_{i \in I} \sum_{q \in \mathcal{Q}^{\ell}_i} \gamma_{i,q}^{\omega,\ell} \left( y_i^{q} - \hat{y}_i^{q,\ell} \right).
	\end{equation}
	Since the subproblem is a linear relaxation, \(\theta^\omega\) is a lower approximation of \(f^\omega\) for the current partition. However, since the validity result depends on the current partition, the cut needs to be modified once the partition is updated to retain the validity result. We assume that the update only refines the partition for each \(i \in I\):
	\begin{definition} \label{definition:refinement}
		For two partitions \(\mathcal{P}^1_i\) and \(\mathcal{P}^2_i\), indexed by \(\mathcal{Q}^1_i\) and \(\mathcal{Q}^2_i\) respectively, where \(\mathcal{P}^2_i\) is a refinement of \(\mathcal{P}^1_i\), we have:
		\begin{equation*}
		\forall q^2 \in \mathcal{Q}^2_i, \exists q^1 \in \mathcal{Q}^1_i \text{ s.t. } \bar{H}^{q^1} \geq \bar{H}^{q^2} \text{ and } \underbar{H}^{q^1} \leq \underbar{H}^{q^1}.
		\end{equation*}
	\end{definition}
	\noi Suppose at the current iteration for each \(i \in I\), the partition is \(\mathcal{P}_i\) indexed by \(\mathcal{Q}_i\), and this partition is updated from past partitions by only a sequence of refinement defined in Definition~\ref{definition:refinement}. Therefore, we can find a set of elements of the current partition,  \(\mathcal{P}_i\) refined from the \(q\)-th element in the partition \(\mathcal{P}^\ell_i\) in the previous iteration \(\ell\). We name such set as a ``descendant set", denoted by \(\Delta_i(\ell,q)\). Cut~\eqref{cons:cut} can then be updated to the following form so that the \(y\) variable has a proper dimension matching the current partition:
	\begin{align} \label{cons:updatedcut}
	& \theta^\omega \geq v^{\omega,\ell} + \sum_{i \in I} \pi_i^{\omega,\ell} (t_i - \hat{t}_i^{\ell}) + \sum_{i \in I} \sum_{j \in J_i} \lambda_{ij}^{\omega,\ell} (x_{ij} - \hat{x}_{ij}^{\ell}) + \nonumber \\
	& \qquad \sum_{i \in I} \sum_{q \in \mathcal{Q}^{\ell}_i} \gamma_{i}^{\omega,\ell,q} \left( \sum_{\tilde{q} \in \Delta_i(\ell,q)} y_i^{\tilde{q}} - \hat{y}_i^{q,\ell} \right) \qquad \forall \ell = 1,2, \dots.
	\end{align}
	We show that, given a partition, \(\mathcal{P}\), which is updated from sequential refinement, \(\mathcal{P}^\ell, \ell = 1,2,\dots\), the cut~\eqref{cons:updatedcut} is a valid lower approximation for function \(g\):
	\begin{proposition} \label{prop:validity}
		Suppose we have a partition, \(\mathcal{P}\), which is indexed by sets \(\mathcal{Q}\), and the sequence of partitions, \(\{\mathcal{P}^\ell\}_{\ell = 1}\), each of which is indexed by sets \(\mathcal{Q}^\ell\). Assuming \(\mathcal{P}\) is a refinement of \(\mathcal{P}^\ell\) for every \(\ell = 1,2, \dots\), for any \(\omega \in \Omega\), we have
		\begin{align} \label{cons:validlb}
		&f^\omega_{\mathcal{P}}(t,x,y) \geq v^{\omega,\ell} + \sum_{i \in I} \pi_i^{\omega,\ell} (t_i - \hat{t}_i^{\ell}) + \sum_{i \in I} \sum_{j \in J_i} \lambda_{ij}^{\omega,\ell} (x_{ij} - \hat{x}_{ij}^{\ell}) + \nonumber \\ 
		& \qquad \qquad \sum_{i \in I} \sum_{q \in \mathcal{Q}^{\ell}_i} \gamma_{i}^{\omega,\ell,q} \left( \sum_{\tilde{q} \in \Delta_i(\ell,q)} y_i^{\tilde{q}} - \hat{y}_i^{q,\ell} \right) \qquad \forall \ell = 1,2, \dots. 
		\end{align}
		at any given feasible \((t,x,y)\).
	\end{proposition}
	\begin{proof}
		We denote the recourse function corresponding to the partition \(\mathcal{P}^{\ell}\) as \(f^\omega_{\mathcal{P}^\ell}(t,x,y)\), where \(y\) has the correct dimension according to \(\mathcal{P}^\ell\). We first prove that 
		\begin{equation} \label{cons:gglb}
		f^\omega_{\mathcal{P}}(t,x,y) \geq f^{\omega}_{\mathcal{P}^\ell}(t,x,\tilde{y}) \qquad \forall \ell = 1,2,\dots
		\end{equation}
		where \[\tilde{y}_i^{q} =  \sum_{\tilde{q} \in \Delta_i(\ell,q)} y_i^{\tilde{q}} \qquad  \forall i \in I, q \in \mathcal{Q}^\ell_i. \]
		Suppose for an \(\omega \in \Omega\) and a \((t,x,y)\), we solve the problem \(S_{\mathcal{P}}^\omega\) and obtain the optimal solution \((t^{\omega,*},x^{\omega,*},G^{\omega,*},F^{\omega,*})\). It is easy to see that by transforming \(F^{\omega,*}\) to \(\tilde{F}^{\omega,*}\) with \[\tilde{F}^{\omega,*,q}_i = \sum_{\tilde{q} \in \Delta_i(\ell,q) }F_i^{\omega,*,\tilde{q}} \qquad  \forall i \in I, q \in \mathcal{Q}^\ell_i;\]
		we obtain a feasible solution \((t^{\omega,*},x^{\omega,*},G^{\omega,*},\tilde{F}^{\omega,*})\) to the recourse problem corresponding to the partition \(\mathcal{P}^\ell\). Therefore, inequality~\eqref{cons:gglb} holds. Furthermore, the cut generated at partition \(\mathcal{P}^\ell\) is
		\[\theta^\omega \geq v^{\omega,\ell} + \sum_{i \in I} \pi_i^{\omega,\ell} (t_i - \hat{t}_i^{\ell}) + \sum_{i \in I} \sum_{j \in J_i} \lambda_{ij}^{\omega,\ell} (x_{ij} - \hat{x}_{ij}^{\ell}) + \sum_{i \in I} \sum_{q \in \mathcal{Q}^{\ell}_i} \gamma_{i}^{\omega,\ell,q} \left( y_i^{q} - \hat{y}_i^{q,\ell} \right),\]
		which means that for any feasible \((t,x,\tilde{y})\), we have 
		\begin{equation} \label{cons:validglb}
		f^\omega_{\mathcal{P}^\ell}(t,x,\tilde{y}) \geq v^{\omega,\ell} + \sum_{i \in I} \pi_i^{\omega,\ell} (t_i - \hat{t}_i^{\ell}) + \sum_{i \in I} \sum_{j \in J_i} \lambda_{ij}^{\omega,\ell} (x_{ij} - \hat{x}_{ij}^{\ell}) + \sum_{i \in I} \sum_{q \in \mathcal{Q}^{\ell}_i} \gamma_{i}^{\omega,\ell,q} \left( \tilde{y}_i^{q} - \hat{y}_i^{q,\ell} \right).
		\end{equation}
		By substituting \(\tilde{y}\) by \(y\) and combining inequalities~\eqref{cons:gglb} and~\eqref{cons:validglb}, we obtain the result of~\eqref{cons:validlb}.
	\end{proof}
	\noi Proposition~\ref{prop:validity} states that if we perform a proper modification on the \(y\) variables to all cuts generated in the past, the modified cuts~\eqref{cons:updatedcut} will be a valid lower approximation for the current recourse function. Therefore, we incorporate the modified cuts~\eqref{cons:updatedcut} in our master problem, given a partition \(\mathcal{P}\) indexed by \(\mathcal{Q}\), which is shown as follows:
	\begin{subequations} \label{prob:masterTightened}
		\begin{align}
		(M_{\mathcal{P}}) \quad z_{\mathcal{P}}^* = \min \quad &p^0 t_T + \sum_{\omega \in \Omega} p^\omega \theta^{\omega}\\
		\text{s.t.} \quad & t_k - t_i \geq D_{i}(1 - \sum_{j \in J_i} x_{ij} e_{ij}) \qquad \qquad \forall \,i \in I, (i,k) \in \mathcal{A} \label{cons:MpSep}\\
		& \sum_{i \in I} \sum_{j \in J_i} b_{ij}x_{ij} \leq B  \label{cons:MpBudget}\\
		& \sum_{j \in J_i} x_{ij} \leq 1  \qquad \qquad \forall \,i \in I \label{cons:MpSingleBudget}\\
		& \sum_{q \in \mathcal{Q}_i} H^{\underbar{\omega}^q} y_i^{q} \leq t_i \leq \sum_{q \in \mathcal{Q}_i} H^{\bar{\omega}^q} y_i^{q} \qquad \qquad \forall i \in I\\
		& \sum_{q \in \mathcal{Q}_i} y^q_i = 1 \qquad \qquad \forall i \in I \label{cons:MpY1}\\
		& \theta^\omega \geq v^{\omega,\ell} + \sum_{i \in I} \pi_i^{\omega,\ell} (t_i - \hat{t}_i^{\ell}) + \sum_{i \in I} \sum_{j \in J_i} \lambda_{ij}^{\omega,\ell} (x_{ij} - \hat{x}_{ij}^{\ell}) \nonumber \\
		&\qquad + \sum_{i \in I} \sum_{q \in \mathcal{Q}^{\ell}_i} \gamma_{i}^{\omega,\ell,q} \left( \sum_{\tilde{q} \in \Delta_i(\ell,q)}y_i^{\tilde{q}} - \hat{y}_i^{q,\ell} \right) \qquad  \forall \omega \in \Omega, \ell = 1, 2, \dots\\
		& y_i^q \in \{0,1\} \qquad \qquad \forall i \in I, q \in \mathcal{Q}_i\\
		& t_i \geq 0 \qquad \qquad \forall \,i \in I\\
		& 0 \leq x_{ij} \leq 1 \qquad \qquad \forall \,i \in I, j \in J_i.
		\end{align}
	\end{subequations}
	We can see that if we keep refining the partition, the generated cuts will become tighter and we will be able to provide an improving lower bound as it progresses. We refine the partition by selecting the element of \(\mathcal{P}^\ell\) indexed by \(q\), \(q \in \mathcal{Q}^\ell_i\), for each activity \(i \in I\), where for some scenarios \(\omega \in \Omega\) with \(H^\omega \in [\underbar{H}^q,\bar{H}^q]\), \(G_i^\omega\) has a fractional value, and divide the interval into three subintervals, each covering approximately the same number of scenarios. The decomposition algorithm is presented as follows:\\
	\begin{algorithm}
		\caption{Partition Based Decomposition algorithm to solve problem~\eqref{prob:extensive}}
		\label{alg:Cut}
		\begin{algorithmic}[1]
			\State Initialize with cut iteration number \(\ell = 0\), lower bound \(LB = 0\), upper bound \(UB = +\infty\), initial partition \(\mathcal{P}^\ell\) with its indexed set \(\mathcal{Q}^\ell\), and specified tolerance parameters \(\epsilon > 0\) and \(\delta > 0\);
			\While{\(\frac{UB - LB}{UB} > \epsilon\)} 
			\State Solve master problem \((M_{\mathcal{P}})\) and obtain solution \(\hat{t}^{\ell}, \hat{x}^{\ell}, \hat{y}^{\ell}, \hat{\theta}^{\ell}\) and optimal value \(z_{P}^*\);
			\If{\(z_{P}^* > LB\)}
			\State Update \(LB = z_{P}^*\);
			\EndIf
			\State For each \(\omega \in \Omega\), solve problem \((S^\omega)\) and obtain \(f^{\omega}(\hat{t}^{\ell},\hat{x}^{\ell})\). 
			\State Calculate \(z^* = p^0 \hat{t}^\ell_T + \sum_{\omega \in \Omega} p^\omega f^{\omega}(\hat{t}^\ell,\hat{x}^\ell)\)
			\If{\(z^* < UB\)} 
			\State Update \(UB := z^*\) and record the best incumbent solution as \(t^* = \hat{t}^\ell, x^* = \hat{x}^\ell\) and \(y^* = \hat{y}^\ell\);
			\EndIf
			\State For each \(\omega \in \Omega\), solve problem \((S_{\mathcal{P}}^\omega)\) given \(\hat{t}^{\ell}, \hat{x}^{\ell}, \hat{y}^{\ell}, \hat{\theta}^{\ell}\) and obtain optimal value \(v^{\omega,\ell}\) and coefficients \(\pi^{\omega,\ell}, \lambda^{\omega,\ell}, \gamma^{\omega,\ell}\);
			\If{\(z^*_{\mathcal{P}} < p^0 \hat{t}_T + \sum_{\omega \in \Omega} p^\omega v^{\omega,\ell} - \delta\)}
			\State Add the cuts of form~\eqref{cons:cut} to the master problem;
			\State Keep \(\mathcal{P}^{\ell + 1} = \mathcal{P}^\ell\) and \(\mathcal{Q}^{\ell + 1} = \mathcal{Q}^\ell\); 
			\State Update \(\ell = \ell + 1\);
			\Else
			\State Refine the partition and obtain the new partition \(\mathcal{P}^{\ell + 1}\) and its indexed sets \(\mathcal{Q}^{\ell + 1}\);
			\State Update \(\ell = \ell + 1\);
			\State Update the previously generated cuts in the master problem to the form of~\eqref{cons:updatedcut};
			\EndIf
			\vspace{0.1cm}
			\EndWhile{\textbf{end while}}
			\State Output \(UB\) as the optimal value of model~\eqref{prob:extensive}, and \(t^*, x^*\) as the optimal solution.
		\end{algorithmic}
	\end{algorithm}
	\noi We prove Algorithm~\ref{alg:Cut} converges in finite number of iterations. Since every partition update is a refinement and we have a finite set of scenario \(\Omega\), we can prove the finite convergence of Algorithm~\ref{alg:Cut} as long as with the finest partition we reach the optimum of problem~\eqref{prob:extensive}.
	\begin{proposition} \label{prop:finestPar}
		If a partition \(\hat{\mathcal{P}}\) has indexed sets \(\hat{\mathcal{Q}}\) and for each \(i \in I\), \(|\hat{\mathcal{Q}}_i| = |\Omega|\) and \(\bar{\omega}^q = \underbar{\omega}^q + 1,\ \forall q \in \hat{\mathcal{Q}}_i\), we have \[z^* = \min_{(t,x,y) \in \mathbb{X}}\ t_T + \sum_{\omega \in \Omega} f^\omega_{\hat{\mathcal{P}}}(t,x,y),\]
		where 
		\begin{equation*}
		\mathbb{X} = \left\{(t,x,y) \left| 
		\begin{aligned}
		& \text{Constraints } \eqref{cons:MpSep}-\eqref{cons:MpY1}\\ 
		&y_i^q \in \{0,1\} \qquad \forall i \in I, q \in \hat{\mathcal{Q}}_i\\
		& t_i \geq 0 \qquad \forall i \in I\\
		& 0 \leq x_{ij} \leq 1 \qquad \forall i \in I, j \in J_i
		\end{aligned}
		\right. \right\}.
		\end{equation*}
	\end{proposition}
	\begin{proof}
		First we can consider the subproblem \((S_\mathcal{P}^\omega)\) as a partial linear relaxation of the original extensive formulation. So \(z^* \leq z^*_\mathcal{P}\) is automatically true.\\
		\newline
		Next we prove that, given the partition in Proposition~\ref{prop:finestPar}, we can construct a feasible solution, \((t^*,x^*,G^*)\), to the extensive formulation~\eqref{prob:extensive} with the same objective value from the optimal solution, \((\hat{t},\hat{x},\hat{y})\), to the problem
		\[\min_{(t,x,y) \in \mathbb{X}}\ t_T + \sum_{\omega \in \Omega} f^\omega_{\hat{\mathcal{P}}}(t,x,y).\]
		Suppose for \(i \in I\), we denote the index of partition where \(y\) variable takes value \(1\) as \(q_i\). Since \(\bar{H}^q = \underbar{H}^{q + 1},\ \forall q \in \hat{\mathcal{Q}}_i\), either \(q_i \in \{q \in \hat{\mathcal{Q}}_i \mid H^\omega \leq \underbar{H}^q\}\) or \(q_i \in \{q \in \hat{\mathcal{Q}}_i \mid H^\omega \geq \bar{H}^q\}\) is true. Thus, constraints~\eqref{cons:syG1t} and~\eqref{cons:syG2t} enforce that \(G_i\) in the problem \((S_{\hat{\mathcal{P}}}^\omega)\) takes binary value because the right-hand side expressions of those two constraints must be \(0\) or \(1\) simultaneously. This means that although subproblems are linear programs, the integrality is implied. Therefore, when we obtain the optimal solution \(\hat{G}^\omega\) from solving problems \((S_{\hat{\mathcal{P}}}^\omega)\) for each \(\omega \in \Omega\), solution \((\hat{t},\hat{x},\hat{G})\) will be feasible for the extensive formulation because \((\hat{t},\hat{x},\hat{y}) \in \mathbb{X}\) and \(G\) variables satisfy the constraints~\eqref{cons:stG1}-\eqref{cons:subH} and binary constraints. This result is equivalent to \(z_{\hat{\mathcal{P}}}^* \geq z^*\). Combining the results above we conclude that \(z^* = \min_{(t,x,y) \in \mathbb{X}}\ t_T + \sum_{\omega \in \Omega} f^\omega_{\hat{\mathcal{P}}}(t,x,y).\)
	\end{proof}
	\begin{theorem} \label{thm:converge}
		Algorithm~\ref{alg:Cut} terminates in finite number of iteration for any \(\epsilon \geq 0\). 
	\end{theorem}
	\begin{proof}
		From Proposition~\ref{prop:finestPar} we know that with the finest partition \(\hat{\mathcal{P}}\) where for each \(i \in I\), \(|\hat{\mathcal{Q}}_i| = |\Omega|\) and \(\bar{H}^q = \underbar{H}^{q + 1},\ \forall q \in \hat{\mathcal{Q}}_i\), solving the problem \(\min_{(t,x,y) \in \mathbb{X}}\ t_T + \sum_{\omega \in \Omega} f^\omega_{\hat{\mathcal{P}}}(t,x,y)\) is equivalent to solving the extensive formulation. Since there are only finite number of scenarios, it takes finite number of steps of refinement to reach the finest partition. \\
		\newline
		For each subproblem, there is only a finite number of possible values of dual variables because each corresponds to one of the finitely many different bases. This means that, for any partition \(\mathcal{P}\), the recourse function \(f^\omega_{\mathcal{P}}\) can be represented by finitely many linear cuts. Therefore, in algorithm~\ref{alg:Cut}, only a finite number of cuts are added for a finite number of partitions before \(UB = z^*\) and \(LB = z^*_{\hat{\mathcal{P}}}\) is achieved, a.k.a. \(\frac{UB - LB}{UB} = 0\).
	\end{proof}
	
	\subsection{Pruning Partitions Using Bound Tightening} \label{subsec:FBBT}
	Feasibility-based and optimization-based bound tightening has been proved powerful in mixed integer nonlinear programming to improve computational performance~\cite{belotti2012fbbt,coffrin2015strengthening,sundar2018OBBT}. Feasibility-based bound tightening (FBBT) process is suitable to our problem because the precedence relationships put limits on some activities that they cannot start before a certain time. For each activity \(i \in I\), we solve the following linear programs to identify the lower bound and the upper bound of the starting time of each activity. 
	\begin{subequations} \label{prob:btminmax}
		\begin{align}
		\min/\max \quad & t_i \\
		\text{s.t.} \quad & \eqref{cons:MSep} - \eqref{cons:Mxbounds}\\
		& \underbar{t}_i \leq t_i \leq \bar{t}_i \qquad \forall i \in I.
		\end{align}
	\end{subequations}
	The bound tightening process starts with a set of initial bounds \(\underbar{t}_i = 0\) and \(\bar{t}_i = T_{\max}\) for each \(i \in I\). We solve model~\eqref{prob:btminmax} iteratively and update \(\bar{t}_i\) and \(\underbar{t}_i\) until the bounds converge respectively.\\
	\newline
	We run FBBT at the beginning of our decomposition method to provide the initial partition \(\mathcal{P}^0\) to start Algorithm~\ref{alg:Cut}. If we can tighten the bounds of some activities, for example, by branch-and-bound or heuristics, we can run FBBT to tighten the bounds for all activities, which leads to a tighter formulation of the subproblems, \(S^{\omega}_{\mathcal{P}}\). \\
	
	\subsection{Obtaining Heuristic Upper Bound} \label{subsec:HUB}
	We observe that it takes many iterations in Algorithm~\ref{alg:Cut} to find a good feasible solution. When there is not a tight upper bound as cutoff value, it takes longer to solve model \(\mathcal{M}_{\mathcal{P}}\). On the other hand, it is fast to solve model~\eqref{prob:extensive} with a small number of scenarios (e.g., 20 scenarios). Solving this small model provides a feasible solution \(\hat{t},\hat{x}\), which can be used to generate an upper bound for the problem with large number of scenarios. Therefore, we bootstrap small subsets of scenarios from the original scenario set, i.e., \(\Omega'_n \subset \Omega,\ n = 1,2,\dots\), and solve model~\eqref{prob:extensive} with each of those subsets to generate upper bound evaluations. Then we select the smallest to serve as the upper bound for model \(\mathcal{M}_{\mathcal{P}}\). \\
	\newline
	There are many ways to generate the subsets \(\Omega'_n\). We observe that it is beneficial to spread the scenarios within each subset in a similar distribution as the original scenario set. We first sort the scenarios so that the scenario with a larger disruption time has a larger index. Suppose we want to generate \(N\) subsets with an equal size \(|\Omega'|\) such that \(N \cdot |\Omega'| = |\Omega|\). The \(n\)-th subset is indexed by:
	\[\Omega'_n = \{n + (j - 1) \cdot |\Omega'|,\ j = 1,2,\dots, N\}.\]
	The upper bound generated using this heuristic is within \(5\%\) of the optimal objective value for every test case. \tcb{In Section~\ref{sec:results} we compare the computational time of the decomposition method with and without the initial upper bound and show the significant performance improvement by adding such a heuristic upper bound.}
	
	\subsection{Magnanti-Wong Type Heuristics on Benders Cuts Generation} \label{subsec:MW}
	For Benders decomposition with a mixed integer master program, it is observed that the subproblems have multiple optimal dual, which means that at a specific incumbent solution, there are multiple valid cuts to generate. Magnanti and Wong~\cite{magnanti1981accelerating} provide a method to select Pareto-optimal cuts. Such Pareto-optimal cuts are stronger than ordinary Benders cuts at the relative interior of the feasible region of the master problem. It means that the generated Pareto-optimal cuts have a higher value when the integrality is relaxed, which helps tighten the linear programming relaxation of the master program.\\
	\newline
	We applies a heuristics that pursues the same goal as Magnanti and Wong~\cite{magnanti1981accelerating} to tighten the cuts at interior points of the feasible region of the master program \((M_\mathcal{P})\). We keep a record of all feasible solutions obtained in the past, \(\hat{t}\) and \(\hat{x}\), find the right \(\hat{y}\) for each of them with the current version of partition, and calculate the average of those points to obtain an average point, (\(t^0,x^0,y^0\)). We then solve the subproblems following the same procedure as in Magnanti and Wong~\cite{magnanti1981accelerating}, using this average point in the place of the core point. For each scenario \(\omega \in \Omega\), first we solve model~\eqref{prob:subTightened} with the current master solution \((\hat{t},\hat{x},\hat{y})\)to obtain the optimal value \(f^*_{\mathcal{P}}(\hat{t},\hat{x},\hat{y})\). Suppose the dual problem of \((S^\omega_\mathcal{P})\) can be represented in a simplified form~\eqref{prob:subdual}; \tcb{see Appendix for the expanded version of model~\eqref{prob:subdual}.}
	\begin{subequations} \label{prob:subdual}
		\begin{align}
		\max_{\pi,\lambda,\gamma,\eta} \quad & \pi^\top (\hat{t} + b_t) + \lambda^\top (\hat{x} + b_x) + \gamma^\top (\hat{y} + b_y) + \eta^\top b \\
		\text{s.t.} \quad & A^\top_{\pi} \pi + A^\top_{\lambda} \lambda + A^\top_{\gamma} \gamma + A^\top_{\eta} \eta \leq c.
		\end{align}
	\end{subequations}
	Given a small error tolerance, \(\epsilon = 10^{-5}\), we solve the maximization problem to obtain enhanced Benders cuts parameters \(\tilde{v}\), \(\pi\), \(\lambda\) and \(\gamma\):
	\begin{subequations} \label{prob:subMW}
		\begin{align}
		\tilde{v} = \max_{\pi,\lambda,\gamma,\eta} \quad & \pi^\top (t^0 + b_t) + \lambda^\top (x^0 + b_x) + \gamma^\top (y^0 + b_y) + \eta^\top b  \\
		\text{s.t.} \quad & \pi^\top (\hat{t} + b_t) + \lambda^\top (\hat{x} + b_x) + \gamma^\top (\hat{y} + b_y) + \eta^\top b \geq (1 - \epsilon) f^*_{\mathcal{P}}(\hat{t},\hat{x},\hat{y}) \\
		& A^\top_{\pi} \pi + A^\top_{\lambda} \lambda + A^\top_{\gamma} \gamma + A^\top_{\eta} \eta \leq c.
		\end{align}
	\end{subequations}
	\noi Our average point (\(t^0,x^0,y^0\)) may not always be in the relative interior of the master problem feasible region: if for all past solutions there exists an \(i \in I\) and \(q \in \mathcal{Q}_i\) such that \(\hat{y}_i^q = 1\), then \(y_i^{0,q}\) takes a binary value for all \(q \in \mathcal{Q}_i\), and does not lie in the relative interior of the master problem feasible region. Although it means our generated cuts may not be Pareto-optimal, they help improve the computational performance, as shown in Table~\ref{table:heuristics} in Section~\ref{sec:results}.
	
	\subsection{Combining Partitioning with Branch-and-Bound} \label{subsec:bbpartition}
	The decomposition method using partitions (Algorithm 1) can be further enhanced by a branch-and-bound process, which helps reduce the number of binary variables added to the master and enables solving simpler MIPs in parallel. The branch-and-bound tree consists of nodes, each corresponding to model~\eqref{prob:masterTightened} with different partitions. The root node starts with the initial partition. For each node, we perform the Benders' decomposition process with the master problem \((\mathcal{M}_{\mathcal{P}})\) subproblems, \((S_{\mathcal{P}}^\omega),\ \forall \omega \in \Omega\), to generate cuts for the node until it converges. The optimal solution of the node provides a lower bound to the original problem~\ref{prob:extensive} since for every \(\omega \in \Omega\), \((S_{\mathcal{P}}^\omega)\) is a relaxation for \((S^\omega)\). We solve \((S^\omega)\) for \(\omega \in \Omega\) to obtain an evaluation of the upper bound. If the gap between this upper bound and the lower bound smaller than the tolerance, we can mark the current node complete and start processing the next available node in the tree. If not, we branch on a scenario \(\hat{\omega}\) with the largest relaxation gap at the optimal solution of the node, \(f^{\hat{\omega}}(\hat{t},\hat{x}) - f^{\hat{\omega}}_{\mathcal{P}}(\hat{t},\hat{x},\hat{y})\), with a specified activity \(\hat{i} \in I\) where subproblem of scenario \(\hat{\omega}\) has a fractional \(G_i\). The current node branches out to two children nodes: one with the constraint \(t_{\hat{i}} \leq H^{\hat{\omega}}\) and the other with the constraint \(t_{\hat{i}} \geq H^{\hat{\omega}}\). Correspondingly, the partition \(\mathcal{Q}_{\hat{i}}\) will be refined because branching creates a natural partition at \(H^{\hat{\omega}}\), and some \(y_{\hat{i}}^{q}\) for the new partition will be forced to take value 0.\\
	\newline
	After this branching process, for each children node, we can still refine the partition on all activities \(i \in I\) similar to the description in Section~\ref{subsec:partition}. The children will inherit the parent node's cuts and they will be updated in a similar fashion of inequality~\eqref{cons:updatedcut}. Suppose for activity \(i \in I\), the current node \(n\) has a partition \(\mathcal{P}_i^n\) indexed by set \(\mathcal{Q}_i^n\); its parent node \(m\) has a partition \(\mathcal{P}_i^m\) indexed by set \(\mathcal{Q}_i^m\), the cuts inherited from node \(m\) will be updated for node \(n\) as:
	\begin{align}\label{cons:updatedcutBB}
	& \theta^\omega \geq v^{\omega,m,\ell} + \sum_{i \in I} \pi_i^{\omega,m,\ell} (t_i - \hat{t}_i^{m,\ell}) + \sum_{i \in I} \sum_{j \in J_i} \lambda_{ij}^{\omega,m,\ell} (x_{ij} - \hat{x}_{ij}^{m,\ell}) + \nonumber \\
	& \qquad \sum_{i \in I} \sum_{q \in \mathcal{Q}^{m}_i} \gamma_{i}^{\omega,m,q} \left( \sum_{\tilde{q} \in \Delta^n_i(m,q)} y_i^{\tilde{q}} - \hat{y}_i^{q,m,\ell} \right) \qquad \forall \ell = 1,2, \dots.
	\end{align}
	Here \(\Delta^n_i(m,q)\) represents the descendant set of the partition \(\mathcal{P}_i^n\) refined from the \(q\)-th element in the partition \(\mathcal{P}_i^m\). The cuts remain valid since the new partitions of the children node are refinements of the parent node partition, even with the branching action. The parent node is marked complete once the refining process is done, and we search for the next available node with the smallest lower bound to perform the Benders decomposition on. \\
	\newline
	There are many rules to select the activity \(\hat{i}\) to branch on. In our observation, the biggest contributor to the relaxation gap, \(f^{\hat{\omega}}(\hat{t},\hat{x}) - f^{\hat{\omega}}_{\mathcal{P}}(\hat{t},\hat{x},\hat{y})\), is that variable \(G\) can take fractional value in relaxation problem \(S_{\mathcal{P}}^\omega\). Since the magnitude of the disruption, \(d_i^\omega\), is usually large in value to model significant effect of the stochastic disruption, a fractional \(G\) can have a large impact on the separation constraint~\eqref{cons:subSep}. When \(d_i^\omega\) has a very large positive value and \(G_i\) is supposed to take value \(1\), the possibility of \(G_i\) being a fractional value close to zero will decrease the separation between activity \(i\) and \(k\) by a large amount, and thus create a large gap between the relaxation problem and the original mixed-integer subproblem. Therefore, when we branch on the scenario \(\hat{\omega}\), suppose the subproblem has a solution \(\hat{G}_i\), we select the activity with the maximum violation measure of \(d_i^{\hat{\omega}} \hat{G}_i\), \(\rho_i^{\hat{\omega}}\):
	\begin{align}
	\rho_i^{\hat{\omega}} = \begin{cases}
	d_i^{\hat{\omega}} \hat{G}_i & \text{if } t_i < H^{\hat{\omega}}\\
	d_i^{\hat{\omega}} (1 - \hat{G}_i) & \text{if } t_i > H^{\hat{\omega}}\\
	\min\{d_i^{\hat{\omega}} \hat{G}_i, d_i^{\hat{\omega}} (1 - \hat{G}_i)\} & \text{otherwise.}
	\end{cases}
	\end{align}
	With all pieces together, we summarize the new algorithm of the partitioning based branch-and-bound decomposition method in Algorithm~\ref{alg:CutBB}. We can perform the algorithm steps on each available node in parallel to improve the time performance.
	\begin{algorithm}
		\caption{Partitioning Based Branch-and-Bound Decomposition algorithm to solve problem~\eqref{prob:extensive}}
		\label{alg:CutBB}
		\begin{algorithmic}[1]
			\State Initialize with specified tolerance parameters \(\epsilon > 0\) and \(\delta > 0\), a global upper bound \(UB\), and the tree of node \(1\) marked available with the following properties: cut iteration number \(\ell_1 = 1\), lower bound \(LB^1\), initial partition \(\mathcal{P}^1\) with its indexed set \(\mathcal{Q}^1\);
			\While{there exists an available node such that \(\frac{UB - LB^n}{UB} > \epsilon\)}
			\State Select the available node \(n\) with smallest \(LB^n\);
			\State Append the inherited cuts from all ancestors of node \(n\) in the form of inequality~\eqref{cons:updatedcutBB};
			\Repeat
			\State Solve master problem \((M_{\mathcal{P}})\) of node \(n\), obtain solution \(\hat{t}^{\ell^n}, \hat{x}^{\ell^n}, \hat{y}^{\ell^n}, \hat{\theta}^{\ell^n}\) 
			
			\hspace{1cm} and optimal value \(z_{\mathcal{P}}^*\);
			\If{\(z_{\mathcal{P}}^* > LB^n\)}
			\State Update \(LB^n = z_{\mathcal{P}}^*\);
			\EndIf
			\State For each \(\omega \in \Omega\), solve problem \((S^\omega)\) and obtain \(f^{\omega}(\hat{t}^{\ell^n},\hat{x}^{\ell^n})\). 
			\State Calculate \(z^* = p^0 \hat{t}^{\ell^n}_T + \sum_{\omega \in \Omega} p^\omega f^{\omega}(\hat{t}^{\ell^n},\hat{x}^{\ell^n})\)
			\If{\(z^* < UB\)} 
			\State Update \(UB := z^*\) and record the best incumbent solution as \(t^* = \hat{t}^{\ell^n}, x^* = \hat{x}^{\ell^n}\) 
			
			\hspace{1.7cm} and \(y^* = \hat{y}^{\ell^n}\);
			\EndIf
			\State For each \(\omega \in \Omega\), solve problem \((S_{\mathcal{P}}^\omega)\) given \(\hat{t}^{\ell^n}, \hat{x}^{\ell^n}, \hat{y}^{\ell^n}, \hat{\theta}^{\ell^n}\)
			
			\hspace{1cm} obtain optimal value \(v^{\omega,\ell^n}\) and coefficients \(\pi^{\omega,\ell^n}, \lambda^{\omega,\ell^n}, \gamma^{\omega,\ell^n}\);
			\State Add the cuts of form~\eqref{cons:cut} to the master problem;
			\State Update \(\ell^n = \ell^n + 1\);
			\Until{\(z^*_{\mathcal{P}} \geq z^* - \delta\)}
			\If{\(\frac{UB - LB^n}{UB} > \epsilon\)}
			\State Branch the node to generate two children nodes \(n_1\) and \(n_2\);
			\State Refine the partition for nodes \(n_1\) and \(n_2\) to obtain \(\mathcal{P}^{n_1}\) and \(\mathcal{P}^{n_2}\), respectively;
			\State Let \(LB^{n_1} = LB^{n_2} = LB^n\);
			\Else
			\State Mark node \(n\) complete;
			\EndIf
			\vspace{0.1cm}
			\EndWhile{\textbf{end while}}
			\State Output \(UB\) as the optimal value of model~\eqref{prob:extensive}, and \(t^*, x^*\) as the optimal solution.
		\end{algorithmic}
	\end{algorithm}
	
	\subsection{Numerical Example of the Partitioning Based Branch-and-Bound Decomposition Method}
	In this section, we use an example to illustrate the process of the partitioning based branch-and-bound decomposition method. Since the size of this example is small, we choose to solve the problem to optimality, i.e., \(\epsilon = 0\). Suppose we have a serial network with five activities, \(i \in I = \{1,2,3,4,5\}\) in Figure~\ref{fig:fiveAct}. 
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{fiveAct}
		\caption{A five-activity serial network to illustrate Algorithm~\ref{alg:CutBB}}
		\label{fig:fiveAct}
	\end{figure}
	\noi Each activity has a duration \(D_i = 1,\ \forall i \in I\), and each activity can be crashed with an option that will decrease the duration by 90\% with one unit of resource consumption, i.e., \(e_{i1} = 0.9,\ \forall i \in I\). The total resource budget \(B = 2\). The probability of no disruption is \(p_0 = 0.2\), and the disruption can occur at four discrete time points: \(H^1 = 1,\ H^2 = 2,\ H^3 = 3,\ H^4 = 4\) with equal probability \(p^\omega = 0.2,\ \forall \omega \in \Omega = \{1,2,3,4\}\). The duration increase by \(d_i^\omega = 10,\ \forall i \in I, \omega \in \Omega\). From this setup, we can bound the starting time of activity from above by \(T_{\max} = 9\). \\
	\newline
	We first tighten the bound of starting time for each activity. Then we can start Algorithm~\ref{alg:CutBB} with the initial node \(1\). The partition of the initial node is:
	\begin{align*}
	&\mathcal{P}_1^1 = \{(0,9)\} \qquad \qquad \;\; \mathcal{Q}_1^1 = \{1\}\\
	&\mathcal{P}_2^1 = \{(0,9)\} \qquad \qquad \;\; \mathcal{Q}_2^1 = \{1\}\\
	&\mathcal{P}_3^1 = \{(0,9)\} \qquad \qquad \;\; \mathcal{Q}_3^1 = \{1\}\\
	&\mathcal{P}_4^1 = \{(0,1),(1,9)\} \qquad  \mathcal{Q}_4^1 = \{1,2\} \qquad y_4^1 = 0\\
	&\mathcal{P}_5^1 = \{(0,2),(2,9)\} \qquad  \mathcal{Q}_5^1 = \{1,2\} \qquad y_5^1 = 0\\
	&\mathcal{P}_T^1 = \{(0,3),(3,9)\} \qquad  \mathcal{Q}_T^1 = \{1,2\} \qquad y_T^1 = 0.
	\end{align*}
	We can perform the Benders decomposition on node \(1\). The process converges to an optimal value \(z^*_{\mathcal{P}} = 4.072\). In the process, we update the upper bound with the best \(z^*\) found in the process, as \(UB = 6.607\). The optimal solution is:
	\begin{align*}
	& \hat{t}_1 = 0 \qquad \qquad \hat{x}_{11} = 0\\
	& \hat{t}_2 = 1 \qquad \qquad \hat{x}_{21} = 0.1124\\
	& \hat{t}_3 = 1.899 \qquad \; \hat{x}_{31} = 0.1124\\
	& \hat{t}_4 = 2.798 \qquad \; \hat{x}_{41} = 0.8860\\
	& \hat{t}_5 = 2.997 \qquad \; \hat{x}_{51} = 0.8892\\
	& \hat{t}_T = 3.2.
	\end{align*}
	At this solution, the largest relaxation gap is incurred at \(\hat{\omega} = 1\) with the value \(f^{\hat{\omega}}(\hat{t},\hat{x}) - f^{\hat{\omega}}_{\mathcal{P}}(\hat{t},\hat{x},\hat{y}) = 8.75\). The optimal solution to the subproblem \(S^1_\mathcal{P}\) has a fractional solution \(G_3 = 0.125\). Since the optimality gap at node 1 is larger than 0, we branch on scenario \(1\) and activity \(3\), creating two children nodes, node \(2\) and node \(3\). Node 2 has an additional constraint, \(t_3 \geq H^1 = 1\) and node 3 has an additional constraint \(t_3 \leq H^1 = 1\). For each activity \(i \in I\), we refine the partition by selecting the scenario with the largest nonzero \(\rho_i^\omega\) for \(\omega \in \Omega\). If for an activity \(i \in I\), there is no scenario with positive \(\rho_i^\omega\), we do not refine the partition for such activity. As stated in Section~\ref{subsec:FBBT}, we can solve a series of linear programs~\eqref{prob:btminmax} to tighten the bounds of starting times for node 2 and node 3, respectively with their additional constraint \(t_3 \geq 1\) and \(t_3 \leq 1\). After refinement and bound tightening, we obtain the partition for node 2 and node 3 as follows:
	\begin{align*}
	& \text{Node 2:}\\
	&\mathcal{P}_1^2 = \{(0,9)\} \qquad \qquad \qquad \quad \mathcal{Q}_1^2 = \{1\}\\
	&\mathcal{P}_2^2 = \{(0,9)\} \qquad \qquad \qquad \quad \mathcal{Q}_2^2 = \{1\}\\
	&\mathcal{P}_3^2 = \{(0,1),(1,9)\} \qquad \qquad \;\; \mathcal{Q}_3^2 = \{1,2\} \qquad \quad  y_3^1 = 0\\
	&\mathcal{P}_4^2 = \{(0,1),(1,2),(2,9)\} \qquad  \mathcal{Q}_4^2 = \{1,2,3\} \qquad y_4^1 = 0\\
	&\mathcal{P}_5^2 = \{(0,2),(2,3),(3,9)\} \qquad  \mathcal{Q}_5^2 = \{1,2,3\} \qquad y_5^1 = 0\\
	&\mathcal{P}_T^2 = \{(0,3),(3,4),(4,9)\} \qquad  \mathcal{Q}_T^2 = \{1,2,3\} \qquad y_T^1 = 0.
	\end{align*}
	\begin{align*}
	& \text{Node 3:}\\
	&\mathcal{P}_1^3 = \{(0,1),(1,9)\} \qquad \qquad \;\; \mathcal{Q}_1^3 = \{1,2\} \qquad \quad y_1^2 = 0\\
	&\mathcal{P}_2^3 = \{(0,1),(1,9)\} \qquad \qquad \;\; \mathcal{Q}_2^3 = \{1,2\} \qquad \quad y_2^2 = 0\\
	&\mathcal{P}_3^3 = \{(0,1),(1,9)\} \qquad \qquad \;\; \mathcal{Q}_3^3 = \{1,2\} \qquad \quad y_3^2 = 0\\
	&\mathcal{P}_4^3 = \{(0,1),(1,2),(2,9)\} \qquad  \mathcal{Q}_4^3 = \{1,2,3\} \qquad y_4^1 = 0\\
	&\mathcal{P}_5^3 = \{(0,2),(2,3),(3,9)\} \qquad  \mathcal{Q}_5^3 = \{1,2,3\} \qquad y_5^1 = 0\\
	&\mathcal{P}_T^3 = \{(0,3),(3,4),(4,9)\} \qquad  \mathcal{Q}_T^3 = \{1,2,3\} \qquad y_T^1 = 0.
	\end{align*}
	We mark node 1 as complete and move on to node 2, which is the available node with the smallest lower bound. Processing node 2 with Benders decomposition yields an optimal solution of 6.1111. The node 2 branches to node 4 and 5, which inherit the cuts and the lower bound from node 2. \\
	\newline
	The next available node with the smallest lower bound is node 3. Node 3 yields an optimal value of 6 and an optimal solution as: 
	\begin{align*}
	& \hat{t}_1 = 0 \qquad \qquad \hat{x}_{11} = 1\\
	& \hat{t}_2 = 0.1 \qquad \quad\; \hat{x}_{21} = \frac{1}{9}\\
	& \hat{t}_3 = 1 \qquad \qquad \hat{x}_{31} = 0\\
	& \hat{t}_4 = 2 \qquad \qquad \hat{x}_{41} = 0\\
	& \hat{t}_5 = 3 \qquad \qquad \hat{x}_{51} = \frac{8}{9}\\
	& \hat{t}_T = 3.2.
	\end{align*}
	The relaxation gap is zero, which means that the upper bound is updated to \(UB = 6\) as well. This leads to a zero optimality gap at node 3. For node 4 and node 5, since their lower bounds are larger than the current upper bound, they will not be processed by the algorithm. The algorithm terminates with the best solution as \(\hat{t}\) and \(\hat{x}\), and the optimal objective value is 6.
	
	\section{Experimental Results} \label{sec:results}
	%	\textcolor{blue}{Test results:
	%	\begin{itemize}
	%		\item Describe the test examples: where do they come from, number of nodes, how are they generated.
	%		\item Cite Sen's paper and describe the implementation.
	%		\item Results.
	%	\end{itemize}}
	In this section, we address the following questions with our computational results:
	\begin{enumerate}
		\item What is the value of model~\eqref{prob:extensive} that takes account of randomness in both timing and magnitude of a disruption? In other words, what are other alternative solutions that are easier to obtain but possibly inferior? How does the quality of the solution to model~\eqref{prob:extensive} compare to those alternative solutions?
		\item How does the solution quality improve as the number of samples used in sample average approximation increases? 
		\item What is the time improvement of Algorithm~\ref{alg:Cut} compared to solving extensive formulation~\eqref{prob:extensive} using state-of-the-art MIP solvers? Other algorithms solving 2SMIP with mixed binary recourse?
	\end{enumerate}
	We first introduce the PERT network used for test and distribution information used to characterize uncertainty in Section~\ref{subsec:example}. In Section~\ref{subsec:value} we construct a series of deterministic and semi-deterministic alternatives to model~\eqref{prob:extensive}, perform out-of-sample tests, and present the better quality result of the solution to model~\eqref{prob:extensive} compared to the alternative ones. We test the effect of different simulation budgets on solution quality and computational performance in Section~\ref{subsec:budget}. Finally in Section~\ref{subsec:time} we present the computational advantage of Algorithm~\ref{alg:Cut} compared to solving extensive formulation.\\
	\newline
	All tests are run on a server with 20 Intel Xeon cores at 3.1 GHz and 256 GB of RAM. All models are constructed using version 0.18.0 of the JuMP package \cite{DunningHuchetteLubin2017} on the Julia platform. All linear programs and mixed integer programs are solved by Gurobi 8.01 \cite{gurobi2016} with default parameters.
	
	\subsection{Test Cases Construction} \label{subsec:example}
	%	\textcolor{blue}{Where we find our tests:
	%		\begin{itemize}
	%			\item Plambeck paper: Case 11
	%			\item V42: Case 14
	%			\item Case 19 from Elmgrabhy
	%			\item Case 55 from Elmgrabhy
	%			\item Randomized network 35, 75 nodes
	%			\item Plambeck paper: Case 110
	%	\end{itemize}}
	\noi Although it is easy to construct an activity network with randomly distributed disruption time and magnitude, not all instances constructed can well illustrate properties of our problem. Therefore, we construct our test cases based on the activity networks used in the previous literature, which have been shown of research value. We use an activity network from Plambeck et al.~\cite{plambeck1996sample} with 11 activities, one from Elmgrabhy~\cite{Elmaghraby77} with 19 activities, and we manually create one activity network with 14 activities and randomly generate one network with 35 activities using the tool \emph{RanGen}~\citep{demeulemeester2003rangen}. In the following section, we use ``Case \(X\)" to denote the test case with \(X\) activities.\\
	\newline
	For every test case, the timing of disruption follows a lognormal distribution since its value has to be nonnegative. The disruption magnitude of activities follows an exponential distribution of which the parameter differs among activities. The exponential distribution can best model the drastic change caused by a disruption.
	\subsection{Value of a Fully Stochastic Model} \label{subsec:value}
	In this section, we compare the quality of five solutions obtained under different possible problem settings to show the value of modeling random timing and magnitude of the disruption. First, we can solve a deterministic project crashing problem assuming no disruption occurs (denoted as ``DET"). Three semi-stochastic alternatives can be constructed assuming: both timing and magnitude of the disruption are deterministic at their expected values (denoted as ``EXP"), the timing is random but the magnitude is at its expected value (denoted as ``\(H\)Only"), and the magnitude is random but the timing is at its expected value (denoted as ``\(d\)Only"). Finally, we construct the full stochastic model where both the timing and the magnitude are random (denoted as ``FULL"). To generate those five solutions, we use a sample of size \(500\). We can obtain a point estimation for the upper bound by plugging each of these solutions in the SAA problem with the original \(500\) samples, and we call this estimation, \(z^*\), as ``in-sample" since these samples are also used to obtain solutions. We also sample 20 batches of samples of \(|\Omega| = 5000\), and obtain the confidence interval of the upper bound estimation, \(\bar{z}\), by testing the solution on these batches. We present the comparison of different solutions of Case 11 in Figure~\ref{fig:value}.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{graphValues}
		\caption{Comparison of quality of alternative solutions to the problem~\eqref{prob:extensive}}
		\label{fig:value}
	\end{figure}
	\noi Figure~\ref{fig:value} shows that the solution quality is poor without considering the uncertainty of disruption timing. When we assume the disruption timing is uncertain, the computational effort required to obtain ``\(H\)Only" solution and the fully stochastic solution is on the same level, since we need to include the same number of binary variables. 
	\begin{table}[H]
		\centering
		\begin{tabular}{ c | l l | l l | l l | l l | l l}
			\hline
			& \multicolumn{2}{c |}{Deterministic} & \multicolumn{2}{c |}{Expected} & \multicolumn{2}{c |}{dOnly} & \multicolumn{2}{c |}{HOnly} & \multicolumn{2}{c}{Full}\\
			& \(z^*\) & CI of \(\bar{z}\) & \(z^*\) & CI of  \(\bar{z}\) & \(z^*\) & CI of \(\bar{z}\) & \(z^*\) & CI of \(\bar{z}\) & \(z^*\) & CI of \(\bar{z}\) \\ \hline
			Case 11 & 118.35 & 112.33 & 114.91 & 98.82 & 98.82 \\
			Case 14 & 114.44 & 108.04 & 110.346 & 98.75 & 98.75 \\
			Case 19 & & & &  & -\\
			Case 35 & & & &  & -\\
			\hline
		\end{tabular}
		\caption{Compare optimal values from alternatives of the disruption model}
		\label{table:value}
	\end{table}
	To further test whether having a fully stochastic model is the best, we run a pair-wise \(t\)-test. The null hypothesis is that whether the difference between the upper bound generated by one alternative solution and that generated by the fully stochastic solution is less than 0. The pair-wise \(t\)-test rejects all null hypotheses, which shows that the difference between an alternative solution is significantly larger than the fully stochastic solution. We can conclude the fully stochastic solution is the best solution, and this justifies the value of having a fully stochastic model, albeit its complexity.
	\subsection{Simulation Budget} \label{subsec:budget}
	We first examine the quality of solutions generated from different sizes of samples. It is well known that the objective value obtained by SAA approaches the objective function of the original problem as the sample size grows to infinity, and the expected value of the SAA objective value improves as the sample size increases~\cite{shapiro2009lectures}. However, when the sample size increases, the computational cost increases as well. Understanding how the solution quality changes according to different sample sizes is important to help us decide a proper sample size while achieving a decent solution. For each test case in Section~\ref{subsec:example}, we first obtain \(20\) batches of the optimal solution to model~\ref{prob:extensive} by Algorithm~\ref{alg:Cut}, with sample sizes \(|\Omega| \in \{10, 50, 75, 100, 200, 300, 400, 500\}\). For each of those solutions, we test against a set of \(5000\) samples and obtain the object value as a point estimation of the upper bound for each batch. We can also obtain the \(95\%\) confidence interval of the lower bound and the upper bound estimation for each sample size. We present the upper bound results in Table~\ref{table:budgetU}, the lower bound results in Table~\ref{table:budgetL} and present visualization of the results with Figure~\ref{fig:budget}.
	\begin{table}[H]
		\centering
		\begin{tabular}{ c | l l l l l l l l}
			\hline
			& 10 & 20 & 50 & 100 & 200 & 500 & 1000 & 2000 \\ \hline
			Case 11& 118.35 & 112.33 & 114.91 & 98.82 & 98.82 & & \\
			Case 14 & 114.44 & 108.04 & 110.346 & 98.75 & 98.75 & &  \\
			Case 19 & & & &  & - & & \\
			\hline
		\end{tabular}
		\caption{Upper bound confidence interval for solutions generated by different budgets.}
		\label{table:budgetU}
	\end{table}
	
	\begin{table}[H]
		\centering
		\begin{tabular}{ c | l l l l l l l l}
			\hline
			& 10 & 20 & 50 & 100 & 200 & 500 & 1000 & 2000 \\ \hline
			Case 11& 118.35 & 112.33 & 114.91 & 98.82 & 98.82 & &  \\
			Case 14 & 114.44 & 108.04 & 110.346 & 98.75 & 98.75 & &  \\
			Case 19 & & & &  & - & & \\
			\hline
		\end{tabular}
		\caption{Lower bound estimation for solutions generated by different sample sizes.}
		\label{table:budgetL}
	\end{table}
	
	\begin{figure}
		\centering
		\includegraphics[width=0.8\textwidth]{case19_budget_ublb}
		\caption{Confidence intervals of the lower/upper bound estimation for different sample sizes.}
		\label{fig:budget}
	\end{figure}
	We can see the gap between the upper bound and the lower bound estimation is decreasing as the sample size increases. A decent solution can be obtained by sampling a moderate number of samples, since the upper bound estimation stabilizes when the sample size is greater than \(100\). However, to achieve a good lower bound estimation requires a large number of samples. This comes from the nature of our uncertainty model, as we need to consider both timing and magnitude of the disruption. 
	\subsection{Computational Performance} \label{subsec:time}
	In this section we present the computational result of our decomposition method. \tcb{We first show the effectiveness of finding a heuristic upper bound and generating Magnanti-Wong heuristic cuts. For all test cases, we use a sample size \(|\Omega| = 500\). In Table~\ref{table:heuristics}, ``UB" means that we only use heuristic upper bound in Section~\ref{subsec:HUB} and generate regular Benders cuts, and ``MW" means that we generate Magnanti-Wong heuristic cuts in Section~\ref{subsec:MW} without a prespecified initial upper bound. We also test the time performance of using neither and using both heuristics.}
	\begin{table}[H]
		\centering		
		\begin{tabular}{ c | l l l l }
			\hline
			& Case 11 & Case 14 & Case 19 & Case 35 \\ \hline
			Neither & & & &  \\
			UB & & & & \\
			MW & & & & \\
			Both & & & & \\
			\hline
		\end{tabular}
		\caption{Computational improvement by utilizing heuristic upper bound generation and Magnanti-Wong heuristic cuts.}
		\label{table:heuristics}
	\end{table}
	\noi Next we show the comparison of time running Algorithm~\ref{alg:Cut}, Algorithm~\ref{alg:CutBB}, and directly solving the extensive formulation~\eqref{prob:extensive} using Gurobi. In each master iteration, we solve a master problem with a small number of binary variables. Although we need to solve multiple rounds of the master problem and the number of binary variables is increasing since the partition is refined in every iteration, we still can observe a significant improvement by using our proposed decomposition method, especially when the sample size is large.
	\begin{table}[H]
		\centering		
		\begin{tabular}{ c | l l l l l l l l l l l l }
			\hline
			&10 & 20 & 50 & 100 & 200 & 300 & 400 & 500 & 750 & 1000 & 1500 & 2000 \\ \hline
			Case 11& 118.35 & 112.33 & 114.91 & 98.82 & 98.82 \\
			Case 14 & 114.44 & 108.04 & 110.346 & 98.75 & 98.75 \\
			Case 19 & & & &  & -\\
			\hline
		\end{tabular}
		\caption{Computational performance for different sample sizes.}
		\label{table:time}
	\end{table}
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{case11_time}
		\caption{Computational performance for different sample sizes.}
		% \(|\Omega| \in \{100, 200, 300, 400, 500,1000\}\
		\label{fig:time}
	\end{figure}
	\section{Conclusions} \label{sec:conclusions}
	In this paper, we establish the concept of stochastic disruption and formulate a two-stage stochastic mixed integer program to model a project crashing optimization problem under the influence of single disruption. We use examples to illustrate the counterintuitive properties of our problem that it is possible to delay the start or crash a shorter activity to accelerate the whole project. Moreover, the computational results justify the need to use a two-stage stochastic mixed integer program to model this problem. It is computationally challenging to solve a two-stage stochastic mixed integer program with binary variables in the second stage. Therefore, we propose a decomposition method which uses the logic relationship to generate strong linear programming relaxation of recourse problems and sequentially partitions the master feasible regions to generate Benders' cuts. The proposed method can significantly improve the computational performance, especially for the large sample sizes, which we show is often required to obtain a good solution/estimation of bounds.\\
	\newline
	There are multiple possible extensions of the results in this paper. First, there is still room to improve the computational performance of the decomposition method. Currently, the refining process is to divide the partition element with fractional \(G\) values into three partitions evenly. This can be enhanced by learning the right partition points so that the lower bound can be tightened faster. In addition, we are working on exploiting the network structures to improve the quality of cuts or prune partitions. 
	\bibliographystyle{plainnat}
	\bibliography{PERT_Bib}
	
\end{document}